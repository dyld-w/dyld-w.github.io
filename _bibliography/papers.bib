---
---

@subarticle{Spears.etal.sub,
  author = {Spears, T. A. and Jacques, B. G. and Howard, M. W. and Sederberg, P. B.},
  title = {Scale-invariant temporal history {(SITH):} optimal slicing of the past in an uncertain world},
  journal = {CoRR},
  volume = {abs/1712.07165},
  year = "Submitted",
	abstract = {In both the human brain and any general artificial intelligence (AI), a representation of the past is necessary to predict the future. However, perfect storage of all experiences is not feasible. One possibility, utilized in many applications, is to retain information about the past in a buffer. A limitation of this approach is that, although events in the buffer are represented with perfect accuracy, the resources necessary to represent information at multiple time scales go up rapidly. Here we present a neurally-plausible, compressed, scale-free memory representation we call Scale-Invariant Temporal History (SITH). This representation covers an exponentially large period of time at the cost of sacrificing temporal accuracy for events further in the past. The form of this decay is scale-invariant and can be shown to be optimal, in that it is able to respond to worlds with a wide range of relevant time scales. We demonstrate the utility of this representation in learning to play video games at different levels of complexity. In these environments, SITH exhibits better learning performance than both a fixed-size buffer history representation and a representation with exponentially decaying features. Whereas the buffer performs well as long as the temporal dependencies can be represented within the buffer, SITH performs well over a much larger range of time scales with the same amount of resources. Finally, we discuss how the application of SITH, along with other human-inspired models of cognition, could improve reinforcement and machine learning algorithms in general.},
  url = {http://arxiv.org/abs/1712.07165},
  archivePrefix = {arXiv},
  eprint = {1712.07165},
  timestamp = {Mon, 13 Aug 2018 16:47:21 +0200},
  biburl = {https://dblp.org/rec/bib/journals/corr/abs-1712-07165},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  arXiv = {1712.07165},
}

@subarticle{Howard.etal.sub,
	title = {Foundations of a temporal {RL}},
	url = {http://arxiv.org/abs/2302.10163},
	doi = {10.48550/arXiv.2302.10163},
	abstract = {Recent advances in neuroscience and psychology show that the brain has access to timelines of both the past and the future. Spiking across populations of neurons in many regions of the mammalian brain maintains a robust temporal memory, a neural timeline of the recent past. Behavioral results demonstrate that people can estimate an extended temporal model of the future, suggesting that the neural timeline of the past could extend through the present into the future. This paper presents a mathematical framework for learning and expressing relationships between events in continuous time. We assume that the brain has access to a temporal memory in the form of the real Laplace transform of the recent past. Hebbian associations with a diversity of synaptic time scales are formed between the past and the present that record the temporal relationships between events. Knowing the temporal relationships between the past and the present allows one to predict relationships between the present and the future, thus constructing an extended temporal prediction for the future. Both memory for the past and the predicted future are represented as the real Laplace transform, expressed as the firing rate over populations of neurons indexed by different rate constants \$s\$. The diversity of synaptic timescales allows for a temporal record over the much larger time scale of trial history. In this framework, temporal credit assignment can be assessed via a Laplace temporal difference. The Laplace temporal difference compares the future that actually follows a stimulus to the future predicted just before the stimulus was observed. This computational framework makes a number of specific neurophysiological predictions and, taken together, could provide the basis for a future iteration of RL that incorporates temporal memory as a fundamental building block.},
	urldate = {2023-05-10},
	publisher = {arXiv},
	author = {Howard, Marc W. and Esfahani, Zahra G. and Le, Bao and Sederberg, Per B.},
	month = feb,
	year = "Submitted",
	note = {arXiv:2302.10163 [q-bio]},
	keywords = {Quantitative Biology - Neurons and Cognition},
  pdf = {Howard.etal.sub.pdf}}

@article{Castagna.etal.2023,
	title = {Modeling brain dynamics and gaze behavior: {Starting} point bias and drift rate relate to frontal midline theta oscillations},
	volume = {268},
	issn = {1053-8119},
	shorttitle = {Modeling brain dynamics and gaze behavior},
	url = {https://www.sciencedirect.com/science/article/pii/S1053811923000204},
	doi = {10.1016/j.neuroimage.2023.119871},
	abstract = {Frontal midline theta oscillatory dynamics have been implicated as an important neural signature of inhibitory control. However, most proactive cognitive control studies rely on behavioral tasks where individual differences are inferred through button presses. We applied computational modeling to further refine our understanding of theta dynamics in a cued anti-saccade task with gaze-contingent eye tracking. Using a drift diffusion model, increased frontal midline theta power during high-conflict, relative to low-conflict, trials predicted a more conservative style of responding through the starting point (bias). During both high- and low-conflict trials, increases in frontal midline theta also predicted improvements in response efficiency (drift rate). Regression analyses provided support for the importance of the starting point bias, which was associated with frontal midline theta over the course of the task above-and-beyond both drift rate and mean reaction time. Our findings provide a more thorough understanding of proactive gaze control by linking trial-by-trial increases of frontal midline theta to a shift in starting point bias facilitating a more neutral style of responding.},
	language = {en},
	urldate = {2023-05-10},
	journal = {NeuroImage},
	author = {Castagna, Peter J. and van Noordt, Stefon and Sederberg, Per B. and Crowley, Michael J.},
	month = mar,
	year = {2023},
	keywords = {Computational psychiatry, Drift-diffusion, Inhibition, Inhibitory control, Saccades},
	pages = {119871},
  pdf = {Castagna.etal.2023.pdf}}

@article{Li.etal.2022,
	title = {Tree {Shrews} as an {Animal} {Model} for {Studying} {Perceptual} {Decision}-{Making} {Reveal} a {Critical} {Role} of {Stimulus}-{Independent} {Processes} in {Guiding} {Behavior}},
	volume = {9},
	copyright = {Copyright © 2022 Li et al.. This is an open-access article distributed under the terms of the Creative Commons Attribution 4.0 International license, which permits unrestricted use, distribution and reproduction in any medium provided that the original work is properly attributed.},
	issn = {2373-2822},
	url = {https://www.eneuro.org/content/9/6/ENEURO.0419-22.2022},
	doi = {10.1523/ENEURO.0419-22.2022},
	abstract = {Decision-making is an essential cognitive process by which we interact with the external world. However, attempts to understand the neural mechanisms of decision-making are limited by the current available animal models and the technologies that can be applied to them. Here, we build on the renewed interest in using tree shrews (Tupaia belangeri) in vision research and provide strong support for them as a model for studying visual perceptual decision-making. Tree shrews learned very quickly to perform a two-alternative forced choice contrast discrimination task, and they exhibited differences in response time distributions depending on the reward and punishment structure of the task. Specifically, they made occasional fast guesses when incorrect responses are punished by a constant increase in the interval between trials. This behavior was suppressed when faster incorrect responses were discouraged by longer intertrial intervals. By fitting the behavioral data with two variants of racing diffusion decision models, we found that the between-trial delay affected decision-making by modulating the drift rate of a time accumulator. Our results thus provide support for the existence of an internal process that is independent of the evidence accumulation in decision-making and lay a foundation for future mechanistic studies of perceptual decision-making using tree shrews.},
	language = {en},
	number = {6},
	urldate = {2023-05-10},
	journal = {eNeuro},
	author = {Li, Chuiwen and McHaney, Kara M. and Sederberg, Per B. and Cang, Jianhua},
	month = nov,
	year = {2022},
	pmid = {36414413},
	note = {Publisher: Society for Neuroscience
Section: Research Article: New Research},
	keywords = {decision-making, sequential sampling model, timed racing diffusion model, tree shrew},
  pdf = {Li.etal.2022.pdf}}

@subarticle{Nadel.Sederberg.sub,
	title = {Memory {Reconsolidation}: {Making} {Predictions} {Better}},
	shorttitle = {Memory {Reconsolidation}},
	url = {https://psyarxiv.com/gr49s/},
	doi = {10.31234/osf.io/gr49s},
	abstract = {Memory reconsolidation refers to the phenomenon whereby a previously consolidated memory, i.e., one that is resistant to interference or disruption, becomes labile due to reactivation, initiating a short window during which that memory can be modified. With a wide range of potential clinical and educational applications, reconsolidation has been demonstrated across multiple domains and timescales, including fear, motor, and episodic memory. This chapter seeks to clarify the psychological processes involved in reconsolidation, making connections to underlying physiological mechanisms, with the goal of providing a framework for understanding why and when reconsolidation takes place. Drawing on reviews of both human and relevant animal studies, this chapter highlights the importance of both context and predictions for determining whether new experiences give rise to new learning or the updating of previously-learned associations.},
	language = {en-us},
	urldate = {2023-05-10},
	publisher = {PsyArXiv},
	author = {Nadel, Lynn and Sederberg, Per Benjamin},
	month = sep,
	year = "Submitted",
	keywords = {Animal Learning and Behavior, Behavioral Neuroscience, Cognitive Neuroscience, Cognitive Psychology, Computational Neuroscience, Learning, Memory, Neuroscience, Social and Behavioral Sciences},
  pdf = {Nadel.Sederberg.sub.pdf}}


@article{Darby.etal.2022,
	title = {Intraobject and extraobject memory binding across early development},
	volume = {58},
	issn = {1939-0599},
	doi = {10.1037/dev0001355},
	abstract = {The ability to bind, or link, different aspects of an experience in memory undergoes protracted development across childhood. Most studies of memory binding development have assessed extraobject binding between an object and some external element such as another object, whereas little work has examined the development of intraobject binding, such as between shape and color features within the same object. In this work, we investigate the development of intra- and extraobject memory binding in five-year-olds, eight-year-olds, and young adults with a memory interference paradigm. Between two experiments, we manipulate whether stimuli are presented as coherent objects (Experiment 1: n5-year-olds = 32, 19 males, 13 females; n8-year-olds = 30, 15 males, 15 females; nadults = 30, 15 males, 15 females), requiring intraobject binding between shape and color features, or as spatially separated features (Experiment 2: n5-year-olds = 24, 16 males, 8 females; n8-year-olds = 41, 19 males, 22 females; nadults = 31, 13 males, 18 females), requiring extraobject binding. To estimate the contributions of different binding structures to performance, we present a novel computational model that mathematically instantiates the memory binding, forgetting, and retrieval processes we hypothesize to underlie performance on the task. The results provide evidence of substantial developmental improvements in both intraobject and extraobject binding of shape and color features between 5 and 8 years of age, as well as stronger intraobject compared with extraobject binding of features in all age groups. These findings provide key insights into memory binding across early development. (PsycInfo Database Record (c) 2022 APA, all rights reserved)},
	journal = {Developmental Psychology},
	author = {Darby, Kevin P. and Sederberg, Per B. and Sloutsky, Vladimir M.},
	year = {2022},
	note = {Place: US
Publisher: American Psychological Association},
	keywords = {Childhood Development, Color, Computational Modeling, Developmental Stages, Early Memories, Forgetting, Human Information Storage},
	pages = {1237--1253},
  pdf = {Darby.etal.2022.pdf}}

@inproceedings{Jacques.etal.2022,
	title = {A deep convolutional neural network that is invariant to time rescaling},
	url = {https://proceedings.mlr.press/v162/jacques22a.html},
	abstract = {Human learners can readily understand speech, or a melody, when it is presented slower or faster than usual. This paper presents a deep CNN (SITHCon) that uses a logarithmically compressed temporal representation at each level. Because rescaling the time of the input results in a translation of loglog{\textbackslash}log time, and because the output of the convolution is invariant to translations, this network can generalize to out-of-sample data that are temporal rescalings of a learned pattern. We compare the performance of SITHCon to a Temporal Convolution Network (TCN) on classification and regression problems with both univariate and multivariate time series. We find that SITHCon, unlike TCN, generalizes robustly over rescalings of about an order of magnitude. Moreover, we show that the network can generalize over exponentially large scales without retraining the weights simply by extending the range of the logarithmically-compressed temporal memory.},
	language = {en},
	urldate = {2023-05-10},
	booktitle = {Proceedings of the 39th {International} {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Jacques, Brandon G. and Tiganj, Zoran and Sarkar, Aakash and Howard, Marc and Sederberg, Per},
	month = jun,
	year = {2022},
	note = {ISSN: 2640-3498},
	pages = {9729--9738},
  pdf = {Jacques.etal.2022.pdf}}

@article{Serino.etal.2022,
	title = {Sense of agency for intracortical brain–machine interfaces},
	volume = {6},
	copyright = {2022 The Author(s), under exclusive licence to Springer Nature Limited},
	issn = {2397-3374},
	url = {https://www.nature.com/articles/s41562-021-01233-2},
	doi = {10.1038/s41562-021-01233-2},
	abstract = {Intracortical brain–machine interfaces decode motor commands from neural signals and translate them into actions, enabling movement for paralysed individuals. The subjective sense of agency associated with actions generated via intracortical brain–machine interfaces, the neural mechanisms involved and its clinical relevance are currently unknown. By experimentally manipulating the coherence between decoded motor commands and sensory feedback in a tetraplegic individual using a brain–machine interface, we provide evidence that primary motor cortex processes sensory feedback, sensorimotor conflicts and subjective states of actions generated via the brain–machine interface. Neural signals processing the sense of agency affected the proficiency of the brain–machine interface, underlining the clinical potential of the present approach. These findings show that primary motor cortex encodes information related to action and sensing, but also sensorimotor and subjective agency signals, which in turn are relevant for clinical applications of brain–machine interfaces.},
	language = {en},
	number = {4},
	urldate = {2023-05-10},
	journal = {Nature Human Behaviour},
	author = {Serino, Andrea and Bockbrader, Marcia and Bertoni, Tommaso and Colachis IV, Sam and Solcà, Marco and Dunlap, Collin and Eipel, Kaitie and Ganzer, Patrick and Annetta, Nick and Sharma, Gaurav and Orepic, Pavo and Friedenberg, David and Sederberg, Per and Faivre, Nathan and Rezai, Ali and Blanke, Olaf},
	month = apr,
	year = {2022},
	note = {Number: 4
Publisher: Nature Publishing Group},
	keywords = {Consciousness, Spinal cord diseases},
	pages = {565--578},
  pdf = {Serino.etal.2022.pdf}}

@article{Darby.Sederberg.2022,
	title = {Transparency, replicability, and discovery in cognitive aging research: {A} computational modeling approach},
	volume = {37},
	issn = {1939-1498},
	shorttitle = {Transparency, replicability, and discovery in cognitive aging research},
	doi = {10.1037/pag0000665},
	abstract = {Healthy aging is associated with deficits in performance on episodic memory tasks. Popular verbal theories of the mechanisms underlying this decrement have primarily focused on inferred changes in associative memory. However, performance on any task is the result of interactions between different neurocognitive mechanisms, such as perceptuomotor, memory, and decision-making processes. As a result, age-related differences in performance could arise from multiple processes, which could lead to incomplete or incorrect conclusions about the sources of aging effects. In addition, standard statistical comparisons of group-level summary statistics, such as mean accuracy, may not provide sufficient information to allow detailed mechanistic explanations of age-related change. We argue that these and other drawbacks of relying exclusively on verbal theories can hamper replicability, transparency, and scientific progress in aging research and psychological science more generally, and that computational modeling is a tool that can address many of these limitations. Computational models make mathematically transparent claims about how latent processes give rise to observed behavior and decompose an individual’s performance into model parameters governing hypothesized mechanisms. In this work, we present a short memory task designed for and analyzed with mechanistic model-based approaches. We provide an example of a computational model and fit the model to data from young and older adults with hierarchical Bayesian techniques in order to (a) detect differences in latent cognitive processes between young and older adults (as well as individual participants), (b) quantitatively compare models to assess different processes that could underlie performance, and (c) simulate data to make predictions for future experiments based on model mechanisms. We argue that computational modeling is a powerful tool to examine age differences in latent processes, make theories more transparent, and facilitate discovery in cognitive aging research. (PsycInfo Database Record (c) 2022 APA, all rights reserved)},
	journal = {Psychology and Aging},
	author = {Darby, Kevin P. and Sederberg, Per B.},
	year = {2022},
	note = {Place: US
Publisher: American Psychological Association},
	keywords = {Age Differences, Aging, Cognitive Aging, Computational Modeling, Episodic Memory, Experimental Replication, Memory, Older Adulthood, Research Transparency, Theories},
	pages = {10--29},
  pdf = {Darby.Sederberg.2022.pdf}}

@inproceedings{Jacques.etal.2021,
	title = {{DeepSITH}: {Efficient} {Learning} via {Decomposition} of {What} and {When} {Across} {Time} {Scales}},
	volume = {34},
	shorttitle = {{DeepSITH}},
	url = {https://proceedings.neurips.cc/paper/2021/hash/e7dfca01f394755c11f853602cb2608a-Abstract.html},
	abstract = {Extracting temporal relationships over a range of scales is a hallmark ofhuman perception and cognition---and thus it is a critical feature of machinelearning applied to real-world problems.  Neural networks are either plaguedby the exploding/vanishing gradient problem in recurrent neural networks(RNNs) or must adjust their parameters to learn the relevant time scales(e.g., in LSTMs). This paper introduces DeepSITH, a deep network comprisingbiologically-inspired Scale-Invariant Temporal History (SITH) modules inseries with dense connections between layers. Each SITH module is simply aset of time cells coding what happened when with a geometrically-spaced set oftime lags.  The dense connections between layers change the definition of whatfrom one layer to the next.  The geometric series of time lags implies thatthe network codes time on a logarithmic scale, enabling DeepSITH network tolearn problems requiring memory over a wide range of time scales. We compareDeepSITH to LSTMs and other recent RNNs on several time series prediction anddecoding tasks. DeepSITH achieves results comparable to state-of-the-artperformance on these problems and continues to perform well even as the delaysare increased.},
	urldate = {2023-05-10},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Jacques, Brandon and Tiganj, Zoran and Howard, Marc and Sederberg, Per B},
	year = {2021},
	pages = {27530--27541},
  pdf = {Jacques.etal.2021.pdf}}

@article{Kirkpatrick.etal.2021,
	title = {Equal evidence perceptual tasks suggest a key role for interactive competition in decision-making},
	volume = {128},
	issn = {1939-1471},
	doi = {10.1037/rev0000284},
	abstract = {The dynamics of decision-making have been widely studied over the past several decades through the lens of an overarching theory called sequential sampling theory (SST). Within SST, choices are represented as accumulators, each of which races toward a decision boundary by drawing stochastic samples of evidence through time. Although progress has been made in understanding how decisions are made within the SST framework, considerable debate centers on whether the accumulators exhibit dependency during the evidence accumulation process; namely, whether accumulators are independent, fully dependent, or partially dependent. To evaluate which type of dependency is the most plausible representation of human decision-making, we applied a novel twist on two classic perceptual tasks; namely, in addition to the classic paradigm (i.e., the unequal-evidence conditions), we used stimuli that provided different magnitudes of equal-evidence (i.e., the equal-evidence conditions). In equal-evidence conditions, response times systematically decreased with increase in the magnitude of evidence, whereas in unequal-evidence conditions, response times systematically increased as the difference in evidence between the two alternatives decreased. We designed a spectrum of models that ranged from independent accumulation to fully dependent accumulation, while also examining the effects of within-trial and between-trial variability (BTV). We then fit the set of models to our two experiments and found that models instantiating the principles of partial dependency provided the best fit to the data. Our results further suggest that mechanisms inducing partial dependency, such as lateral inhibition, are beneficial for understanding complex decision-making dynamics, even when the task is relatively simple. (PsycInfo Database Record (c) 2021 APA, all rights reserved)},
	journal = {Psychological Review},
	author = {Kirkpatrick, Ryan P. and Turner, Brandon M. and Sederberg, Per B.},
	year = {2021},
	note = {Place: US
Publisher: American Psychological Association},
	keywords = {Bayesian Analysis, Decision Making, Decision Theory, Models, Perceptual Stimulation, Reaction Time, Sampling (Experimental), Statistical Inference, Statistical Probability, Task, Task Complexity},
	pages = {1051--1087},
  pdf = {Kirkpatrick.etal.2021.pdf}}


@article{Weichart.etal.2021,
	title = {Quantifying mechanisms of cognition with an experiment and modeling ecosystem},
	volume = {53},
	issn = {1554-3528},
	url = {https://doi.org/10.3758/s13428-020-01534-w},
	doi = {10.3758/s13428-020-01534-w},
	abstract = {Although there have been major strides toward uncovering the neurobehavioral mechanisms involved in cognitive functions like memory and decision making, methods for measuring behavior and accessing latent processes through computational means remain limited. To this end, we have created SUPREME (Sensing to Understanding and Prediction Realized via an Experiment and Modeling Ecosystem): a toolbox for comprehensive cognitive assessment, provided by a combination of construct-targeted tasks and corresponding computational models. SUPREME includes four tasks, each developed symbiotically with a mechanistic model, which together provide quantified assessments of perception, cognitive control, declarative memory, reward valuation, and frustrative nonreward. In this study, we provide validation analyses for each task using two sessions of data from a cohort of cognitively normal participants (N = 65). Measures of test-retest reliability (r: 0.58–0.75), stability of individual differences (ρ: 0.56–0.70), and internal consistency (α: 0.80–0.86) support the validity of our tasks. After fitting the models to data from individual subjects, we demonstrate each model’s ability to capture observed patterns of behavioral results across task conditions. Our computational approaches allow us to decompose behavior into cognitively interpretable subprocesses, which we can compare both within and between participants. We discuss potential future applications of SUPREME, including clinical assessments, longitudinal tracking of cognitive functions, and insight into compensatory mechanisms.},
	language = {en},
	number = {5},
	urldate = {2023-05-10},
	journal = {Behavior Research Methods},
	author = {Weichart, Emily R. and Darby, Kevin P. and Fenton, Adam W. and Jacques, Brandon G. and Kirkpatrick, Ryan P. and Turner, Brandon M. and Sederberg, Per B.},
	month = oct,
	year = {2021},
	keywords = {Cognitive assessment, Computational psychiatry, Model-based analysis, Validation},
	pages = {1833--1856},
  pdf = {Weichart.etal.2021.pdf}}

@inproceedings{Graves.etal.2021,
	title = {Extensions and {Application} of the {Robust} {Shared} {Response} {Model} to {Electroencephalography} {Data} for {Enhancing} {Brain}-{Computer} {Interface} {Systems}},
	doi = {10.1109/SIEDS52267.2021.9483745},
	abstract = {Brain Computer Interfaces (BCI) decode electroencephalography (EEG) data collected from the human brain to predict subsequent behavior. While this technology has promising applications, successfully implementing a model is challenging. The typical BCI control application requires many hours of training data from each individual to make predictions of intended activity specific to that individual. Moreover, there are individual differences in the organization of brain activity and low signal-to-noise ratios in noninvasive measurement techniques such as EEG. There is a fundamental bias-variance trade-off between developing a single model for all human brains vs. an individual model for each specific human brain. The Robust Shared Response Model (RSRM) attempts to resolve this tradeoff by leveraging both the homogeneity and heterogeneity of brain signals across people. RSRM extracts components that are common and shared across individual brains, while simultaneously learning unique representations between individual brains. By learning a latent shared space in conjunction with subject-specific representations, RSRM tends to result in better predictive performance on functional magnetic resonance imaging (fMRI) data relative to other common dimension reduction techniques. To our knowledge, we are the first research team attempting to expand the domain of RSRM by applying this technique to controlled experimental EEG data in a BCI setting. Using the openly available Motor Movement/ Imagery dataset, the decoding accuracy of RSRM exceeded models whose input was reduced by Principal Component Analysis (PCA), Independent Component Analysis (ICA), and subject-specific PCA. The results of our experiments suggest that RSRM can recover distributed latent brain signals and improve decoding accuracy of BCI tasks when dimension reduction is implemented as a feature engineering step. Future directions of this work include augmenting state-of-the art BCI with efficient reduced representations extracted by RSRM. This could enhance the utility of BCI technology in the real world. Furthermore, RSRM could have wide-ranging applications across other machine-learning applications that require classification of naturalistic data using reduced representations.},
	booktitle = {2021 {Systems} and {Information} {Engineering} {Design} {Symposium} ({SIEDS})},
	author = {Graves, Andrew J. and Clayton, Cory and Soh, Joon Yuhl and Yohe, Gabe and Sederberg, Per B.},
	month = apr,
	year = {2021},
	keywords = {Brain modeling, Brain-computer interface, Brain-computer interfaces, Data models, Electroencephalography, Functional magnetic resonance imaging, Machine learning, Training, Training data},
	pages = {1--6},
  pdf = {Graves.etal.2021.pdf}}


@inproceedings{Anand.etal.2021,
	title = {Improving {Brain} {Computer} {Interfaces} {Using} {Deep} {Scale}-{Invariant} {Temporal} {History} {Applied} to {Scalp} {Electroencephalogram} {Data}},
	doi = {10.1109/SIEDS52267.2021.9483789},
	abstract = {Brain Computer Interface (BCI) applications employ machine learning to decode neural signals through time to generate actions. One issue facing such machine learning algorithms is how much of the past they need to decode the present. DeepSITH (Deep Scale-Invariant Temporal History), is a deep neural network with layers inspired by how the mammalian brain represents recent vs. less-recent experience. A single SITH layer maintains a log-compressed representation of the past that becomes less accurate with older events, unlike other approaches that maintain a perfect copy of events regardless of how far in the past they occurred. By stacking layers of this compressed representation, we hypothesized that DeepSITH would be able to decode patterns of neural activity from farther in the past and combine them efficiently to guide the BCI in the present. We tested our approach with the Kaggle "Grasp and Lift challenge" dataset. This motor movement dataset has 12 subjects, 10 series of 30 grasp and lift trials per subject, with 6 classes of events to decode. We benchmark DeepSITH performances on this dataset against another common machine learning technique for integrating features over extended time scales, long short-term memory (LSTM). DeepSITH reproducibly achieves higher accuracy in predicting motor movement events than LSTM, and also takes significantly fewer epochs and less memory to train, in comparison to LSTM. In summary, DeepSITH can efficiently process more data, with increased prediction accuracy and learning speed. This result shows that DeepSITH is an advantageous model to consider when developing BCI technologies.},
	booktitle = {2021 {Systems} and {Information} {Engineering} {Design} {Symposium} ({SIEDS})},
	author = {Anand, Gaurav and Ansari, Arshiya and Dobrenz, Beverly and Wang, Yibo and Jacques, Brandon G. and Sederberg, Per B.},
	month = apr,
	year = {2021},
	keywords = {Computational modeling, Machine learning, Machine learning algorithms, Memory management, Neural activity, Scalp, Stacking},
	pages = {1--6},
  pdf = {Anand.etal.2021.pdf}}

@article{Weichart.Sederberg.2021,
	title = {Individual differences in attention allocation during a two-dimensional inhibitory control task},
	volume = {83},
	issn = {1943-393X},
	url = {https://doi.org/10.3758/s13414-020-02160-6},
	doi = {10.3758/s13414-020-02160-6},
	abstract = {Visual attention is often through to take the form of a spotlight or zoom lens that gradually focuses on goal-relevant features of a stimulus over the course of a trial. Several lines of evidence suggest that for spatially contiguous stimuli, the spotlight naturally takes on the shape of a horizontally biased ellipse. Analyses of group-level behavior in the presence of horizontally versus vertically configured stimuli, however, potentially obfuscate an important source of between-subject variability in the early stages of attentional processing. In the current study, we used a two-dimensional flanker task paradigm and nested variants of a model of within-trial attention and decision mechanisms to investigate individual differences in spotlight shapes. To account for the influence of distractor stimuli in both horizontal and vertical positions relative to the target, we operationalized the attentional spotlight as the density function for a bivariate normal distribution within our models. Horizontal and vertical shape parameters governing the spotlight were constrained to be equal in one model variant, and were allowed to vary in the other. Within-subject comparisons of Bayesian goodness-of-fit statistics revealed a general preference for an elliptical rather than a circular spotlight. Follow-up analyses, however, demonstrated substantial variability in spotlight shapes across subjects. Although data from most subjects were best captured by a horizontally biased elliptical spotlight, we observed individual differences in the extent of the bias, with some subjects even demonstrating a circular or vertically biased elliptical spotlight.},
	language = {en},
	number = {2},
	urldate = {2023-05-10},
	journal = {Attention, Perception, \& Psychophysics},
	author = {Weichart, Emily R. and Sederberg, Per B.},
	month = feb,
	year = {2021},
	keywords = {Attention: theoretical and computational models, Cognitive and attentional control},
	pages = {676--684},
  pdf = {Weichart.Sederberg.2021.pdf}}

@article{Bahg.etal.2020,
	title = {Real-time {Adaptive} {Design} {Optimization} {Within} {Functional} {MRI} {Experiments}},
	volume = {3},
	issn = {2522-087X},
	url = {https://doi.org/10.1007/s42113-020-00079-7},
	doi = {10.1007/s42113-020-00079-7},
	abstract = {Efficient data collection is an important goal in cognitive neuroimaging studies because of the high cost of data acquisition. One method of improving efficiency is to maximize the informativeness of the data collected on each trial. We propose an Adaptive Design Optimization (Cavagnaro et al. Neural Computation 22, 887–905 2010; Myung et al. Journal of Mathematical Psychology 57, 53–67 2013) procedure to optimize the sequencing of stimuli for model-based functional neuroimaging studies. Our method uses the Joint Modeling Framework (Turner et al. NeuroImage 72, 193–206 2013, 2019) to maximize the information learned about how the brain produces a behavior by integrating over neural and behavioral data simultaneously. We validate our method in simulation and real-world experiments by showing how Adaptive Design Optimization proposes the optimal stimulus sequence to reduce uncertainty and improve accuracy from a Bayesian perspective.},
	language = {en},
	number = {4},
	urldate = {2023-05-10},
	journal = {Computational Brain \& Behavior},
	author = {Bahg, Giwon and Sederberg, Per B. and Myung, Jay I. and Li, Xiangrui and Pitt, Mark A. and Lu, Zhong-Lin and Turner, Brandon M.},
	month = dec,
	year = {2020},
	keywords = {fMRI, Joint modeling framework, Model-based cognitive neuroscience, Optimal experimental design},
	pages = {400--429},
  pdf = {Bagh.etal.2020.pdf}}

@article{Weichart.etal.2020b,
	title = {A model of dynamic, within-trial conflict resolution for decision making},
	volume = {127},
	issn = {1939-1471},
	doi = {10.1037/rev0000191},
	abstract = {Growing evidence for moment-to-moment fluctuations in visual attention has led to questions about the impetus and time course of cognitive control. These questions are typically investigated with paradigms like the flanker task, which require participants to inhibit an automatic response before making a decision. Connectionist modeling work suggests that between-trial changes in attention result from fluctuations in conflict—as conflict occurs, attention needs to be upregulated to resolve it. Current sequential sampling models (SSMs) of within-trial effects, however, suggest that attention focuses on a goal-relevant target as a function of time. We propose that within-trial changes in cognitive control and attention are emergent properties of the dynamics of the decision itself. We tested our hypothesis by developing a set of SSMs, each making alternative assumptions about attention modulation and evidence accumulation mechanisms. Combining the SSM framework with likelihood-free Bayesian approximation methods allowed us to conduct quantified comparisons between subject-level fits. Models included either time- or control-based attention mechanisms, and either strongly- (via feedforward inhibition) or weakly correlated (via leak and lateral inhibition) evidence accumulation mechanisms. We fit all models to behavioral data collected in variants of the flanker task, one accompanied by EEG measures. Across three experiments, we found converging evidence that control-based attention processes in combination with evidence accumulation mechanisms governed by leak and lateral inhibition provided the best fits to behavioral data, and uniquely mapped onto observed decision-related signals in the brain. (PsycInfo Database Record (c) 2020 APA, all rights reserved)},
	journal = {Psychological Review},
	author = {Weichart, Emily R. and Turner, Brandon M. and Sederberg, Per B.},
	year = {2020},
	note = {Place: US
Publisher: American Psychological Association},
	keywords = {Cognitive Control, Conflict, Conflict Resolution, Connectionism, Decision Making, Electroencephalography, Test Construction, Visual Attention},
	pages = {749--777},
  pdf = {Weichart.etal.2020b.pdf}}

@article{Zhen.etal.2020,
	series = {75 {Annual} {Scientific} {Convention} and {Meeting}},
	title = {A {Bayesian} {Joint} {Model} for {Risk}-{Taking} and {Momentary} {Mood} {Reveals} the {Importance} of {Subjective}, {Non}-{Linear} {Utility} {Curves}},
	volume = {87},
	issn = {0006-3223},
	url = {https://www.sciencedirect.com/science/article/pii/S0006322320310179},
	doi = {10.1016/j.biopsych.2020.02.905},
	language = {en},
	number = {9, Supplement},
	urldate = {2023-05-10},
	journal = {Biological Psychiatry},
	author = {Zheng, Charles and Saha, DIPTA and Nielson, Dylan and Keren, Hanna and Pereira, Francisco and Stringaris, Argyris and Fenton, Adam and Sederberg, Per},
	month = may,
	year = {2020},
	pages = {S353},
  pdf = {Zhen.etal.2020.pdf}}

@article{Weichart.etal.2020a,
	title = {Cognitive {Task} {Performance} {During} {Titration} {Predicts} {Deep} {Brain} {Stimulation} {Treatment} {Efficacy}: {Evidence} {From} a {Case} {Study}},
	volume = {11},
	issn = {1664-0640},
	shorttitle = {Cognitive {Task} {Performance} {During} {Titration} {Predicts} {Deep} {Brain} {Stimulation} {Treatment} {Efficacy}},
	url = {https://www.frontiersin.org/articles/10.3389/fpsyt.2020.00030},
	abstract = {Device titration is a major challenge when using deep brain stimulation (DBS) to treat behavioral disorders. Unlike in movement disorders, there is no reliable real-time clinical feedback for changes in complex behaviors resulting from DBS. Here, a female patient receiving DBS of the nucleus accumbens for the treatment of morbid obesity underwent cognitive testing via the flanker task alongside traditional methods of device titration. One set of stimulation parameters administered during titration resulted in acute cognitive improvement (p = 0.033) and increased frontal engagement as measured by electroencephalography (left anterior: p = 0.007, right anterior: p = 0.005) relative to DBS-OFF. The same parameters resulted in the most weight-loss during long-term continuous stimulation (47.8 lbs lost in 129 days) compared to the results of other stimulation settings. Diffusion tensor imaging analyses showed increased connectivity to dorsal attention networks and decreased connectivity to the default mode network for optimal parameters (p {\textless} 0.01). Our results provide evidence that targeted cognitive testing is a potentially useful tool for capturing acute effects of DBS stimulation during titration and predicting long-term treatment outcomes.Clinical Trial Registrationwww.ClinicalTrials.gov, identifier: NCT01512134.},
	urldate = {2023-05-10},
	journal = {Frontiers in Psychiatry},
	author = {Weichart, Emily R. and Sederberg, Per B. and Sammartino, Francesco and Krishna, Vibhor and Corrigan, John D. and Rezai, Ali R.},
	year = {2020},
  pdf = {Weichart.etal.2020a.pdf}}

@article{Siefke.etal.2019,
	title = {A context-change account of temporal distinctiveness},
	volume = {47},
	issn = {1532-5946},
	url = {https://doi.org/10.3758/s13421-019-00925-5},
	doi = {10.3758/s13421-019-00925-5},
	abstract = {The distinctiveness effect refers to the finding that items that stand out from other items in a learning set are more likely to be remembered later. Traditionally, distinctiveness has been defined based on item features; specifically, an item is deemed to be distinctive if its features are different from the features of other to-be-learned items. We propose that distinctiveness can be redefined based on context change—distinctive items are those with features that deviate from the others in the current temporal context, a recency-weighted running average of experience—and that this context change modulates learning. We test this account with two novel experiments and introduce a formal mathematical model that instantiates our proposed theory. In the experiments, participants studied lists of words, with each word appearing on one of two background colors. Within each list, each color was used for 50 percent of the words, but the sequence of the colors was controlled so that runs of the same color for that list were common in Experiment 1 and common, rare, or random in Experiment 2. In both experiments, participants’ source memory for background color was enhanced for items where the color changed, especially if the change occurred after a stable run without color changes. Conversely, source memory was not significantly better for nonchanges after runs of alternating colors with each item. This pattern is inconsistent with theories of learning based on prediction error, but is consistent with our context-change account.},
	language = {en},
	number = {6},
	urldate = {2023-05-10},
	journal = {Memory & Cognition},
	author = {Siefke, Brian M. and Smith, Troy A. and Sederberg, Per B.},
	month = aug,
	year = {2019},
	keywords = {Context effects, Distinctiveness, Memory, Source memory, Temporal context},
	pages = {1158--1172},
  pdf = {Siefke.etal.2019.pdf}}

@article{Tiganj.etal.2019,
	title = {Estimating {Scale}-{Invariant} {Future} in {Continuous} {Time}},
	volume = {31},
	issn = {0899-7667},
	url = {https://doi.org/10.1162/neco_a_01171},
	doi = {10.1162/neco_a_01171},
	abstract = {Natural learners must compute an estimate of future outcomes that follow from a stimulus in continuous time. Widely used reinforcement learning algorithms discretize continuous time and estimate either transition functions from one step to the next (model-based algorithms) or a scalar value of exponentially discounted future reward using the Bellman equation (model-free algorithms). An important drawback of model-based algorithms is that computational cost grows linearly with the amount of time to be simulated. An important drawback of model-free algorithms is the need to select a timescale required for exponential discounting. We present a computational mechanism, developed based on work in psychology and neuroscience, for computing a scale-invariant timeline of future outcomes. This mechanism efficiently computes an estimate of inputs as a function of future time on a logarithmically compressed scale and can be used to generate a scale-invariant power-law-discounted estimate of expected future reward. The representation of future time retains information about what will happen when. The entire timeline can be constructed in a single parallel operation that generates concrete behavioral and neural predictions. This computational mechanism could be incorporated into future reinforcement learning algorithms.},
	number = {4},
	urldate = {2023-05-10},
	journal = {Neural Computation},
	author = {Tiganj, Zoran and Gershman, Samuel J. and Sederberg, Per B. and Howard, Marc W.},
	month = apr,
	year = {2019},
	pages = {681--709},
  pdf = {Tiganj.etal.2019.pdf}}

@article{Schwemmer.etal.2018,
	abstract = {Brain--computer interface (BCI) neurotechnology has the potential to reduce disability associated with paralysis by translating neural activity into control of assistive devices1--9. Surveys of potential end-users have identified key BCI system features10--14, including high accuracy, minimal daily setup, rapid response times, and multifunctionality. These performance characteristics are primarily influenced by the BCI's neural decoding algorithm1,15, which is trained to associate neural activation patterns with intended user actions. Here, we introduce a new deep neural network16 decoding framework for BCI systems enabling discrete movements that addresses these four key performance characteristics. Using intracortical data from a participant with tetraplegia, we provide offline results demonstrating that our decoder is highly accurate, sustains this performance beyond a year without explicit daily retraining by combining it with an unsupervised updating procedure3,17--20, responds faster than competing methods8, and can increase functionality with minimal retraining by using a technique known as transfer learning21. We then show that our participant can use the decoder in real-time to reanimate his paralyzed forearm with functional electrical stimulation (FES), enabling accurate manipulation of three objects from the grasp and release test (GRT)22. These results demonstrate that deep neural network decoders can advance the clinical translation of BCI technology.},
	Author = {Schwemmer, Michael A. and Skomrock, Nicholas D. and Sederberg, Per B. and Ting, Jordyn E. and Sharma, Gaurav and Bockbrader, Marcia A. and Friedenberg, David A.},
	Da = {2018/11/01},
	Date-Added = {2019-04-18 18:47:58 +0000},
	Date-Modified = {2019-04-18 18:47:58 +0000},
	Doi = {10.1038/s41591-018-0171-y},
	Id = {Schwemmer2018},
	Isbn = {1546-170X},
	Journal = {Nature Medicine},
	Number = {11},
	Pages = {1669--1676},
	Title = {Meeting brain--computer interface user performance expectations using a deep neural network decoding framework},
	Ty = {JOUR},
	Url = {https://doi.org/10.1038/s41591-018-0171-y},
	Volume = {24},
	Year = {2018},
	Bdsk-Url-1 = {https://doi.org/10.1038/s41591-018-0171-y},
	pdf = {Schwemmer.etal.2018.pdf}}

@article{Sreekumar.etal.2018,
	abstract = {The human posteromedial cortex, which includes core regions of the default mode network (DMN), is thought to play an important role in episodic memory. However, the nature and functional role of representations in these brain regions remain unspecified. Nine participants (all female) wore smartphone devices to record episodes from their daily lives for multiple weeks, each night indicating the personally-salient attributes of each episode. Participants then relived their experiences in an fMRI scanner cued by images from their own lives. Representational Similarity Analysis revealed a broad network, including parts of the DMN, that represented personal semantics during autobiographical reminiscence. Within this network, activity in the right precuneus reflected more detailed representations of subjective contents during vivid relative to non-vivid, recollection. Our results suggest a more specific mechanism underlying the phenomenology of vivid autobiographical reminiscence, supported by rich subjective content representations in the precuneus, a hub of the DMN previously implicated in metacognitive evaluations during memory retrieval.},
	Author = {Sreekumar, Vishnu and Nielson, Dylan M. and Smith, Troy A. and Dennis, Simon J. and Sederberg, Per B.},
	Da = {2018/10/08},
	Date-Added = {2019-04-18 18:40:13 +0000},
	Date-Modified = {2019-04-18 18:40:13 +0000},
	Doi = {10.1038/s41598-018-32879-0},
	Id = {Sreekumar2018},
	Isbn = {2045-2322},
	Journal = {Nature Scientific Reports},
	Number = {1},
	Pages = {14899},
	Title = {The experience of vivid autobiographical reminiscence is supported by subjective content representations in the precuneus},
	Ty = {JOUR},
	Url = {https://doi.org/10.1038/s41598-018-32879-0},
	Volume = {8},
	Year = {2018},
	Bdsk-Url-1 = {https://doi.org/10.1038/s41598-018-32879-0},
	pdf = {Sreekumar.etal.2018.pdf}}

@article{OConnell.etal.2018,
  abstract = {Distributed representations of scene categories are consistent between color photographs (CPs) and line drawings (LDs) in the parahippocampal place area (PPA) and the retrosplenial cortex (RSC), as shown using multi-voxel pattern analysis (MVPA). Here, we used repetition suppression (RS) to further investigate the degree of representational convergence between CPs and LDs of natural scenes. MVPA and RS can capture different aspects of visual representations, and RS may prove useful in elucidating important differences in the representations of CPs and LDs of natural scenes. We performed an event-related fMRI experiment, including image-repetitions either within-type (i.e., CP to CP or LD to LD) or between-types (CP to LD, LD to CP). We found significant RS for within-type repetitions in PPA, RSC and the occipital place area (OPA), but did not observe RS for between-types repetitions. By contrast, scene categories were decodable from activity patterns evoked by both CPs and LDs using SVM classification for both within-type decoding and between-types cross-decoding. We conclude that there are representational differences between CPs and LDs in scene-selective cortex despite a category-level correspondence.},
  title = "Representational differences between line drawings and photographs of natural scenes: A dissociation between multi-voxel pattern analysis and repetition suppression",
  journal = "Neuropsychologia",
  volume = "117",
  pages = "513--519",
  year = "2018",
  number = "0028-3932",
  doi = "https://doi.org/10.1016/j.neuropsychologia.2018.06.013",
  url = "http://www.sciencedirect.com/science/article/pii/S0028393218302859",
  author = "O’Connell, T. P. and Sederberg, P. B. and Walther, D. B.",
  keywords = "natural scene perception, fMRI, multi-voxel pattern analysis, repetition suppression",
  pdf = {OConnell.etal.2018.pdf},
}

@article{Palestro.etal.2018b,
  abstract = {Traditional models of choice-response time assume that sensory evidence accumulates for choice alternatives until a threshold amount of evidence has been obtained. Although some researchers have characterized the threshold as varying randomly from trial to trial, these investigations have all assumed that the threshold remains fixed across time within a trial. Despite decades of successful applications of these models to a variety of experimental manipulations, the time-invariance assumption has recently been called into question, and a time-variant alternative implementing collapsing decision thresholds has been proposed instead. Here, we investigated the fidelity of the collapsing threshold assumption by assessing relative model fit to data from a highly constrained experimental design that coupled a within-subject mixture of two classic response time paradigms-interrogation and free response-within a random dot motion (RDM) task. Overall, we identified strong evidence in favor of collapsing decision thresholds, suggesting that subjects may adopt a dynamic decision policy due to task characteristics, specifically to account for the mixture of response time paradigms and motion strengths across trials in the mixed response signal task. We conclude that time-variant mechanisms may serve as a viable explanation for the strategy used by human subjects in our task.},
  author = "Palestro, J. J. and Weichart, E. R. and Sederberg, P. B. and Turner, B. M.",
  title = "Some task demands induce collapsing bounds: Evidence from a behavioral analysis",
  journal = "Psychonomic Bulletin Review",
  year = "2018",
  month = "Aug",
  day = "01",
  volume = "25",
  number = "4",
  pages = "1225--1248",
  number = "1531-5320",
  doi = "10.3758/s13423-018-1479-9",
  url = "https://doi.org/10.3758/s13423-018-1479-9",
  pdf = {Palestro.etal.2018b.pdf},
}

@article{Scharre.etal.2018,
  abstract = {The study objective was to evaluate the safety and efficacy of deep brain stimulation (DBS) at the ventral capsule/ventral striatum (VC/VS) region to specifically modulate frontal lobe behavioral and cognitive networks as a novel treatment approach for Alzheimer's disease (AD) patients. This is a non-randomized phase I prospective open label interventional trial of three subjects with matched comparison groups. AD participants given DBS for at least 18 months at the VC/VS target were compared on the Clinical Dementia Rating-Sum of Boxes (CDR-SB), our primary outcome clinical measure, to matched groups without DBS from the AD Neuroimaging Initiative (ADNI) cohort. Serial 2-Deoxy-2-[18F]fluoro-D-glucose (FDG) positron emission tomography (PET) images of AD participants were also compared longitudinally over time. Three AD DBS participants were matched to subjects from the ADNI cohort. All participants tolerated DBS well without significant adverse events. All three AD DBS participants had less performance decline and two of them meaningfully less decline over time on our primary outcome measure, CDR-SB, relative to matched comparison groups from the ADNI using score trajectory slopes. Minimal changes or increased metabolism on FDG-PET were seen in frontal cortical regions after chronic DBS at the VC/VS target. The first use of DBS in AD at a frontal lobe behavior regulation target (VC/VS) was well-tolerated and revealed less performance decline in CDR-SB. Frontal network modulation to improve executive and behavioral deficits should be furthered studied in AD.},
  title = {Deep Brain Stimulation of Frontal Lobe Networks to Treat Alzheimer’s Disease},
  author = {Scharre, D. W. and Weichart, E. R. and Nielson, D. M. and Zhang, J. and Agrawal, P. and Sederberg, P. B. and Knopp, M. V. and Rezai, A. R.},
  journal = {Journal of Alzheimer’s Disease},
  volume = {62},
  number = {2},
  pages = {621--633},
  year = {2018},
  publisher = {IOS Press},
  pdf = {Scharre.etal.2018.pdf},
}

@article{Palestro.etal.2018a,
  abstract = {A growing synergy between the fields of cognitive neuroscience and mathematical psychology has sparked the development of several unique statistical approaches exploiting the benefits of both disciplines (Turner, Forstmann et al., 2017). One approach in particular, called joint modeling, attempts to model the covariation between the parameters of “submodels” intended to capture important patterns in each stream of data. Joint models present an interesting opportunity to transcend conventional levels of analyses (e.g., Marr’s hierarchy; Marr, 1982) by providing fully integrative models (Love, 2015). In this manuscript, we provide a tutorial of two flavors of joint models — the Directed and Covariance approaches. Computational procedures have been developed to apply these approaches to a number of cognitive tasks, yet neither have been made accessible to a wider audience. Here, we provide a step-by-step walkthrough on how to develop submodels of each stream of data, as well as how to link the important model parameters to form one cohesive model. For convenience, we provide code that uses the Just Another Gibbs Sampler (Plummer, 2003) software to perform estimation of the model parameters. We close with a demonstration of the approach applied to actual data from a contrast discrimination task where activation parameters of early visual areas are directly mapped to the drift rate parameter in a simplified version of the diffusion decision model (Ratcliff, 1978).},
  title = "A tutorial on joint models of neural and behavioral measures of cognition",
  journal = "Journal of Mathematical Psychology",
  volume = "84",
  pages = "20--48",
  year = "2018",
  number = "0022-2496",
  doi = "https://doi.org/10.1016/j.jmp.2018.03.003",
  url = "http://www.sciencedirect.com/science/article/pii/S0022249617301335",
  author = "Palestro, J. J. and Bahg, G. and Sederberg, P. B. and Lu, Z.-L. and Steyvers, M. and Turner, B. M.",
  keywords = "Model-based cognitive neuroscience, Joint models, Neural and behavioral measures, Bayesian modeling",
  pdf = {Palestro.etal.2018a.pdf},
}

@article{Gravina.Sederberg.2017,
  abstract = {Theories of time and space in memory have traditionally focused on their role in dividing experience into discrete episodes, despite the arbitrary nature of these divisions. We offer an alternative characterization that focuses on the fundamentally predictive role of perception and memory. In this account, perceptual hierarchies in sensory cortex detect patterns of feature-change across a logarithmic continuum of scales in time and space, which allows them to efficiently converge on nuanced, yet short-range, predictions of the present situation. Time and space emerge from this continuum as representations of feature-distance that provide a measure of the relevance of non-simultaneous experiences, allowing for long-range associations, mental time-travel, and predictions that go far beyond the immediate moment. This reframing of the nature and role of time and space in memory has implications for both the interpretation of existing findings and the design of future experiments.},
  title = "The neural architecture of prediction over a continuum of spatiotemporal scales",
  journal = "Current Opinion in Behavioral Sciences",
  volume = "17",
  pages = "194--202",
  year = "2017",
  note = "Memory in time and space",
  number = "2352-1546",
  doi = "https://doi.org/10.1016/j.cobeha.2017.09.001",
  url = "http://www.sciencedirect.com/science/article/pii/S2352154616302844",
  author = "Gravina, M. T. and Sederberg, P. B.",
  pdf = {Gravina.Sederberg.2017.pdf},
}

@article{Nielson.Sederberg.2017,
    abstract = {Mixed effects models provide significant advantages in sensitivity and flexibility over typical statistical approaches to neural data analysis, but mass univariate application of mixed effects models to large neural datasets is computationally intensive. Threshold free cluster enhancement also provides a significant increase in sensitivity, but requires computationally-intensive permutation-based significance testing. Not surprisingly, the combination of mixed effects models with threshold free cluster enhancement and nonparametric permutation-based significance testing is currently completely impractical. With mixed effects for large datasets (MELD) we circumvent this impasse by means of a singular value decomposition to reduce the dimensionality of neural data while maximizing signal. Singular value decompositions become unstable when there are large numbers of noise features, so we precede it with a bootstrap-based feature selection step employing threshold free cluster enhancement to identify stable features across subjects. By projecting the dependent data into the reduced space of the singular value decomposition we gain the power of a multivariate approach and we can greatly reduce the number of mixed effects models that need to be run, making it feasible to use permutation testing to determine feature level significance. Due to these innovations, MELD is much faster than an element-wise mixed effects analysis, and on simulated data MELD was more sensitive than standard techniques, such as element-wise t-tests combined with threshold-free cluster enhancement. When evaluated on an EEG dataset, MELD identified more significant features than the t-tests with threshold free cluster enhancement in a comparable amount of time.},
    author = {Nielson, D. M. AND Sederberg, P. B.},
    journal = {PLOS ONE},
    publisher = {Public Library of Science},
    title = {MELD: Mixed effects for large datasets},
    year = {2017},
    month = {08},
    volume = {12},
    url = {https://doi.org/10.1371/journal.pone.0182797},
    pages = {1--21},
    number = {8},
    doi = {10.1371/journal.pone.0182797},
    pdf = {Nielson.Sederberg.2017.pdf},
}

@article{Turner.etal.2016,
  abstract = {Recent advancements in Bayesian modeling have allowed for likelihood-free posterior estimation. Such estimation techniques are crucial to the understanding of simulation-based models, whose likelihood functions may be difficult or even impossible to derive. One particular class of simulation-based models that have not yet benefited from the progression of Bayesian methods is the class of neurologically-plausible models of choice response time, in particular the Leaky, Competing Accumulator (LCA) model and the Feed-Forward Inhibition (FFI) model. These models are unique because their architecture was designed to embody actual neuronal properties such as inhibition, leakage, and competition. Currently, these models have not been formally compared by way of principled statistics such as the Bayes factor. Here, we use a recently developed algorithm–the probability density approximation method–to fit these models to empirical data consisting of a classic speed accuracy trade-off manipulation. Using this approach, we find some discrepancies between an assortment of model fit statistics. For some participants, one model appears to be superior when one fit statistic is used, while another appears superior when a different statistic is used. However, for 13 of the 20 participants, one model wins by all of the fit metrics considered. The FFI wins in 5 of these cases, while the LCA wins, often by a wide margin, for the others.},
  title = "Bayesian analysis of simulation-based models",
  journal = "Journal of Mathematical Psychology",
  volume = "72",
  pages = "191--199",
  year = "2016",
  note = "Bayes Factors for Testing Hypotheses in Psychological Research: Practical Relevance and New Developments",
  number = "0022-2496",
  doi = "https://doi.org/10.1016/j.jmp.2014.10.001",
  url = "http://www.sciencedirect.com/science/article/pii/S0022249614000637",
  author = "Turner, B. M. and Sederberg, P. B. and McClelland, J. L.",
  keywords = "Bayes factor, Likelihood-free inference, Simulation models, Neurologically plausible cognitive models, Probability density approximation method, Leaky Competing Accumulator model, Feed Forward Inhibition model",
  pdf = {Turner.etal.2016.pdf},
}

@article{Ratcliff.etal.2016,
  abstract = {Recent work in perceptual decision-making has shown that although two distinct neural components differentiate experimental conditions (e.g., did you see a face or a car), only one tracked the evidence guiding the decision process. In the memory literature, there is a distinction between a fronto-central evoked potential measured with EEG beginning at 350 ms that seems to track familiarity and a late parietal evoked potential that peaks at 600 ms that tracks recollection. Here, we applied single-trial regressor analysis (similar to multivariate pattern analysis MVPA) and diffusion decision modeling to EEG and behavioral data from two recognition memory experiments to test whether these two components contribute to the recognition decision process. The regressor analysis only involved whether an item was studied or not and did not involve any use of the behavioral data. Only the EEG activity that distinguishes studied from not studied items at about 600 ms following each test item onset predicted the diffusion model drift rate derived from the behavioral choice and reaction times but only for studied items. When drift rate was made a linear function of the trial-level regressor values, the estimate for studied items was different than zero. This showed that the later EEG activity indexed the trial-to-trial variability in drift rate for studied items. Our results provide strong evidence that only a single EEG component reflects evidence being used in the decision process.},
  title = "A single trial analysis of EEG in recognition memory: Tracking the neural correlates of memory strength",
  journal = "Neuropsychologia",
  volume = "93",
  pages = "128--141",
  year = "2016",
  number = "0028-3932",
  doi = "https://doi.org/10.1016/j.neuropsychologia.2016.09.026",
  url = "http://www.sciencedirect.com/science/article/pii/S0028393216303633",
  author = "Ratcliff, R. and Sederberg, P. B. and Smith, T. A. and Childers, R.",
  keywords = "Diffusion model, Recognition memory, EEG, Single-trial regressor, Reaction time",
  pdf = {Ratcliff.etal.2016.pdf},
}

@{Bouton.etal.2016,
  abstract = {Millions of people worldwide suffer from diseases that lead to paralysis through disruption of signal pathways between the brain and the muscles. Neuroprosthetic devices are designed to restore lost function and could be used to form an electronic 'neural bypass' to circumvent disconnected pathways in the nervous system. It has previously been shown that intracortically recorded signals can be decoded to extract information related to motion, allowing non-human primates and paralysed humans to control computers and robotic arms through imagined movements. In non-human primates, these types of signal have also been used to drive activation of chemically paralysed arm muscles. Here we show that intracortically recorded signals can be linked in real-time to muscle activation to restore movement in a paralysed human. We used a chronically implanted intracortical microelectrode array to record multiunit activity from the motor cortex in a study participant with quadriplegia from cervical spinal cord injury. We applied machine-learning algorithms to decode the neuronal activity and control activation of the participant's forearm muscles through a custom-built high-resolution neuromuscular electrical stimulation system. The system provided isolated finger movements and the participant achieved continuous cortical control of six different wrist and hand motions. Furthermore, he was able to use the system to complete functional tasks relevant to daily living. Clinical assessment showed that, when using the system, his motor impairment improved from the fifth to the sixth cervical (C5-C6) to the seventh cervical to first thoracic (C7-T1) level unilaterally, conferring on him the critical abilities to grasp, manipulate, and release objects. This is the first demonstration to our knowledge of successful control of muscle activation using intracortically recorded signals in a paralysed human. These results have significant implications in advancing neuroprosthetic technology for people worldwide living with the effects of paralysis.},
  author={Bouton, C. E. and Shaikhouni, A. and Annetta, N. V. and Bockbrader, M. A. and Friedenberg, D. A. and Nielson, D. M. and Sharma, G. and Sederberg, P. B. and Glenn, Brad. C. and Mysiw, W. J. and Morgan, A. G. and Deogaonkar, M. and Rezai, A. R.},
  title = {Restoring cortical control of functional movement in a human with quadriplegia},
  journal = {Nature},
  year = {2016},
  month = {Apr},
  day = {13},
  publisher = {Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved. SN  -},
  volume = {533},
  pages = {247--250},
  url = {http://dx.doi.org/10.1038/nature17435},
  pdf = {Bouton.etal.2016.pdf},
}

@article{Hasinski.Sederberg.2016,
  abstract = {Previous research has shown that face-sensitive brain regions, such as the fusiform face area (FFA) and anterior inferior temporal lobe (aIT), not only respond selectively to face stimuli, but also respond uniquely to individual faces. A common factor in the existing literature is that face stimuli in these experiments are highly familiar to participants, usually by design. We set out to investigate to what extent familiarity correlates with the emergence of face-specific information in face-sensitive regions by testing novel faces with only a single repetition. Our results, consistent with a familiarity hypothesis, demonstrate that the FFA and aIT show face-specific information only when participants demonstrate subsequent memory for those faces. Functionally-defined regions that are not believed to process faces holistically showed no face-specific information, regardless of subsequent memory. To our knowledge, this is the first demonstration of face-specific information in face-sensitive regions for stimuli that were not highly familiar. These results contribute to our understanding of how individuating information comes to be represented in face-sensitive regions and suggest that this process can take place even after a single repetition of a particular face.},
  title = "Trial-level information for individual faces in the fusiform face area depends on subsequent memory",
  journal = "NeuroImage",
  volume = "124",
  pages = "526--535",
  year = "2016",
  number = "1053-8119",
  doi = "https://doi.org/10.1016/j.neuroimage.2015.08.065",
  url = "http://www.sciencedirect.com/science/article/pii/S1053811915007867",
  author = "Hasinski, A. E. and Sederberg, P. B.",
  keywords = "Face perception, Face memory, Fusiform face area, Anterior inferior temporal lobes, fMRI",
  pdf = {Hasinski.Sederberg.2016.pdf},
}

@article{Rezai.etal.2016,
  abstract = {BACKGROUND:
  Severe traumatic brain injury (TBI) damages the frontal lobes and connecting networks, which impairs executive functions, including the ability to self-regulate. Despite significant disabling effects, there are few treatment options in the chronic phase after injury.

  OBJECTIVE:
  To investigate the safety and potential effectiveness of deep brain stimulation (DBS) for individuals with chronic, disabling TBI and problems of behavioral and emotional self-regulation.

  METHODS:
  This study was an open-label, prospective design with serial assessments of behavioral outcomes and positron emission tomography 2 years after DBS implantation. Four participants 6 to 21 years after severe TBIs from automobile crashes were included. Although alert and volitional, all experienced significant executive impairments, including either impulsivity or reduced initiation. DBS implants were placed bilaterally in the nucleus accumbens and anterior limb of the internal capsule to modulate the prefrontal cortex.

  RESULTS:
  The procedure was safe, and all participants had improved functional outcomes. Two years after implantation, 3 met a priori criteria for improvement on the Mayo-Portland Adaptability Inventory-4. Improvement was due largely to better emotional adjustment, although 1 participant showed marked increases in multiple domains. Significant improvement in a composite score of functional capacity indicated improved independence in self-care and activities of daily living. The pattern of change in cognition corresponded with changes in activation of the prefrontal cortex observed in serial scanning.

  CONCLUSION:
  This first study of DBS to this target for severe TBI supports its safety and suggests potential effectiveness to improve function years after injury. The primary impact was on behavioral and emotional adjustment, which in turn improved functional independence.},
  author = {Rezai, A. R. and Sederberg, P. B. and Bogner, J. and Nielson, D. M. and Zhang, J. and Mysiw, W. J. and Knopp, M. V. and Corrigan, J. D.},
  title = {Improved Function After Deep Brain Stimulation for Chronic, Severe Traumatic Brain Injury},
  journal = {Neurosurgery},
  volume = {79},
  number = {2},
  pages = {204--211},
  year = {2016},
  doi = {10.1227/NEU.0000000000001190},
  url = {http://dx.doi.org/10.1227/NEU.0000000000001190},
  eprint = {/oup/backfile/content_public/journal/neurosurgery/79/2/10.1227_neu.0000000000001190/5/00006123-201608000-00013.pdf},
  pdf = {Rezai.etal.2016.pdf},
}

@article{Deogaonkar.etal.2016,
  abstract = {INTRODUCTION:
  The neurophysiological basis of pain relief due to spinal cord stimulation (SCS) and the related cortical processing of sensory information are not completely understood. The aim of this study was to use resting state functional magnetic resonance imaging (rs-fMRI) to detect changes in cortical networks and cortical processing related to the stimulator-induced pain relief.

  METHODS:
  Ten patients with complex regional pain syndrome (CRPS) or neuropathic leg pain underwent thoracic epidural spinal cord stimulator implantation. Stimulation parameters associated with "optimal" pain reduction were evaluated prior to imaging studies. Rs-fMRI was obtained on a 3 Tesla, Philips Achieva MRI. Rs-fMRI was performed with stimulator off (300TRs) and stimulator at optimum (Opt, 300 TRs) pain relief settings. Seed-based analysis of the resting state functional connectivity was conducted using seeds in regions established as participating in pain networks or in the default mode network (DMN) in addition to the network analysis. NCUT (normalized cut) parcellation was used to generate 98 cortical and subcortical regions of interest in order to expand our analysis of changes in functional connections to the entire brain. We corrected for multiple comparisons by limiting the false discovery rate to 5%.

  RESULTS:
  Significant differences in resting state connectivity between SCS off and optimal state were seen between several regions related to pain perception, including the left frontal insula, right primary and secondary somatosensory cortices, as well as in regions involved in the DMN, such as the precuneus. In examining changes in connectivity across the entire brain, we found decreased connection strength between somatosensory and limbic areas and increased connection strength between somatosensory and DMN with optimal SCS resulting in pain relief. This suggests that pain relief from SCS may be reducing negative emotional processing associated with pain, allowing somatosensory areas to become more integrated into default mode activity.

  CONCLUSION:
  SCS reduces the affective component of pain resulting in optimal pain relief. Study shows a decreased connectivity between somatosensory and limbic areas associated with optimal pain relief due to SCS.},
  title = {Spinal Cord Stimulation (SCS) and Functional Magnetic Resonance Imaging (fMRI): Modulation of Cortical Connectivity With Therapeutic SCS},
  author = {Deogaonkar, M. and Sharma, M. and Oluigbo, C. and Nielson, D. M. and Yang, X. and Vera-Portocarrero, L. and Molnar, G. F. and Abduljalil, A. and Sederberg, P. B. and Knopp, M. and Rezai, A. R.},
  journal = {Neuromodulation: Technology at the Neural Interface},
  volume = {19},
  number = {2},
  pages = {142–-153},
  year = {2016},
  publisher = {Springer},
  pdf = {Deogaonkar.etal.2016.pdf},
}

@article{Manns.etal.2015,
  abstract = {Recent research in humans has used formal models of temporal context, broadly defined as a lingering representation of recent experience, to explain a wide array of recall and recognition memory phenomena. One difficulty in extending this work to studies of experimental animals has been the challenge of developing a task to test temporal context effects on performance in rodents. The current study presents results from a novel object recognition memory paradigm that was adapted from a task used in humans and demonstrates a temporal context repetition effect in rats. Specifically, the findings indicate that repeating the first two objects from a once-encountered sequence of three objects incidentally cues memory for the third object, even in its absence. These results reveal that temporal context influences item memory in rats similar to the manner in which it influences memory in humans and also highlight a new task for future studies of temporal context in experimental animals.},
  title = {A temporal context repetition effect in rats during a novel object recognition memory task},
  author = {Manns J. R., Galloway C. R., and Sederberg P. B.},
  journal = {Animal Cognition},
  volume = {18},
  number = {5},
  pages = {1031--1037},
  year = {2015},
  publisher = {Springer},
  pdf = {Manns.etal.2015.pdf},
}

@article{Ziniel.etal.2015,
  abstract = {For the problem of binary linear classification and feature selection, we propose algorithmic approaches to classifier design based on the generalized approximate message passing (GAMP) algorithm, recently proposed in the context of compressive sensing. We are particularly motivated by problems where the number of features greatly exceeds the number of training examples, but where only a few features suffice for accurate classification. We show that sum-product GAMP can be used to (approximately) minimize the classification error rate and max-sum GAMP can be used to minimize a wide variety of regularized loss functions. Furthermore, we describe an expectation-maximization (EM)-based scheme to learn the associated model parameters online, as an alternative to cross-validation, and we show that GAMP's state-evolution framework can be used to accurately predict the misclassification rate. Finally, we present a detailed numerical study to confirm the accuracy, speed, and flexibility afforded by our GAMP-based approaches to binary linear classification and feature selection.},
  title = {Binary Linear Classification and Feature Selection via Generalized Approximate Message Passing},
  author = {Ziniel, J. and Schniter, P. and Sederberg, P. B.},
  journal = {Signal Processing, IEEE Transactions on},
  volume = {63},
  number = {8},
  pages = {2020--2032},
  year = {2015},
  publisher = {IEEE},
  pdf = {Ziniel.etal.2015.pdf},
}

@inproceedings{Polyn.Sederberg.2014,
  abstract = {The memory theorist Endel Tulving referred to the ability to search through one's memories, and revisit events and episodes from one's past, as mental time travel. This process involves the reactivation of past mental states reflecting the perceptual and conceptual characteristics of the original experience. Widely distributed neural circuitry is engaged in the service of memory search, and the dynamics of these circuits are reflected in rhythmic oscillatory signals at widespread frequencies, recorded both in the local field around neurons and more globally at the scalp. Retrieved-context theory provides a theoretical bridge between the behavioral phenomena exhibited by participants in memory search tasks, and the neural signals reflecting the dynamics of the underlying circuitry. Computational models based on this theory make broad predictions regarding the representational structure of neural activity recorded during these tasks. In recent work, researchers have used multivariate analytic techniques on topographic patterns of oscillatory neural activity to confirm critical predictions of retrieved-context theory. We review the cognitive theory motivating this recent work, and the analytic techniques being developed to create integrated neural-behavioral models of human memory search.},
  title = {Brain rhythms in mental time travel},
  author = {Polyn, S. M. and Sederberg, P. B.},
  journal = {NeuroImage},
  volume = {85},
  pages = {678--684},
  year = {2014},
  publisher = {Elsevier},
  pdf = {Polyn.Sederberg.2014.pdf},
}

@inproceedings{Paul.etal.2015,
  abstract = {Temporal patterns within complex sound signals, such as music, are not merely processed after they are heard. We also focus attention to upcoming points in time to aid perception, contingent upon regularities we perceive in the sounds’ inherent rhythms. Such organized predictions are endogenously maintained as meter— the patterning of sounds into hierarchical timing levels that manifest as strongand weakevents. Models of neural oscillations provide potential means for how meter could arise in the brain, but little evidence of dynamic neural activity has been offered. To this end, we conducted a study instructing participants to imagine two-based or three-based metric patterns over identical, equally-spaced sounds while we recorded the electroencephalogram (EEG). In the three-based metric pattern, multivariate analysis of the EEG showed contrasting patterns of neural oscillations between strong and weak events in the delta (2–4 Hz) and alpha (9–14 Hz), frequency bands, while theta (4–9 Hz) and beta (16–24 Hz) bands contrasted two hierarchically weaker events. In two-based metric patterns, neural activity did not drastically differ between strong and weak events. We suggest the findings reflect patterns of neural activation and suppression responsible for shaping perception through time.},
  title = {Imagined Temporal Groupings Tune Oscillatory Neural Activity for Processing Rhythmic Sounds},
  author = {Paul, B. T. and Sederberg, P. B. and Feth, L. L.},
  journal = {Timing \& Time Perception},
  volume = {3},
  pages = {172--188},
  year = {2015},
  publisher = {Brill},
  pdf = {Paul.etal.2015.pdf},
}

@inproceedings{Hayes.etal.2015,
  abstract = {Recent reports of training-induced gains on fluid intelligence tests have fueled an explosion of interest in cognitive training-now a billion-dollar industry. The interpretation of these results is questionable because score gains can be dominated by factors that play marginal roles in the scores themselves, and because intelligence gain is not the only possible explanation for the observed control-adjusted far transfer across tasks. Here we present novel evidence that the test score gains used to measure the efficacy of cognitive training may reflect strategy refinement instead of intelligence gains. A novel scanpath analysis of eye movement data from 35 participants solving Raven's Advanced Progressive Matrices on two separate sessions indicated that one-third of the variance of score gains could be attributed to test-taking strategy alone, as revealed by characteristic changes in eye-fixation patterns. When the strategic contaminant was partialled out, the residual score gains were no longer significant. These results are compatible with established theories of skill acquisition suggesting that procedural knowledge tacitly acquired during training can later be utilized at posttest. Our novel method and result both underline a reason to be wary of purported intelligence gains, but also provide a way forward for testing for them in the future.},
  title = {Do we really become smarter when our fluid-intelligence test scores improve?},
  author = {Hayes, T. R. and Petrov, A. A. and Sederberg, P. B.},
  journal = {Intelligence},
  volume = {48},
  pages = {1--14},
  year = {2015},
  publisher = {Elsevier},
  pdf = {Hayes.etal.2015.pdf},
}

@inproceedings{Gershman.etal.2014,
  abstract = {This paper extends earlier work on spatial modeling of fMRI data to the temporal domain, providing a framework for analyzing high temporal resolution brain imaging modalities such as electroencapholography (EEG). The central idea is to decompose brain imaging data into a covariate-dependent superposition of functions defined over continuous time and space (what we refer to as topographic latent sources). The continuous formulation allows us to parametrically model spatiotemporally localized activations. To make group-level inferences, we elaborate the model hierarchically by sharing sources across subjects. We describe a variational algorithm for parameter estimation that scales efficiently to large data sets. Applied to three EEG data sets, we find that the model produces good predictive performance and reproduces a number of classic findings. Our results suggest that topographic latent sources serve as an effective hypothesis space for interpreting spatiotemporal brain imaging data.},
  title = {Decomposing spatiotemporal brain patterns into topographic latent sources},
  author = {Gershman, S. J. and Blei, D. M. and Norman, K. A. and Sederberg, P. B.},
  journal = {NeuroImage},
  volume = {98},
  pages = {91--102},
  year = {2014},
  publisher = {Elsevier},
  pdf = {Gershman.etal.2014.pdf},
}

@article{Turner.Sederberg.2014,
  abstract = {Recent advancements in Bayesian modeling have allowed for likelihood-free posterior estimation. Such estimation techniques are crucial to the understanding of simulation-based models, whose likelihood functions may be difficult or even impossible to derive. However, current approaches are limited by their dependence on sufficient statistics and/or tolerance thresholds. In this article, we provide a new approach that requires no summary statistics, error terms, or thresholds and is generalizable to all models in psychology that can be simulated. We use our algorithm to fit a variety of cognitive models with known likelihood functions to ensure the accuracy of our approach. We then apply our method to two real-world examples to illustrate the types of complex problems our method solves. In the first example, we fit an error-correcting criterion model of signal detection, whose criterion dynamically adjusts after every trial. We then fit two models of choice response time to experimental data: the linear ballistic accumulator model, which has a known likelihood, and the leaky competing accumulator model, whose likelihood is intractable. The estimated posterior distributions of the two models allow for direct parameter interpretation and model comparison by means of conventional Bayesian statistics-a feat that was not previously possible.},
  title = {A generalized, likelihood-free method for posterior estimation},
  author = {Turner, B. M. and Sederberg, P. B.},
  journal = {Psychonomic Bulletin \& Review},
  volume = {21},
  number = {2},
  pages = {227--250},
  year = {2014},
  publisher = {Springer},
  pdf = {Turner.Sederberg.2014.pdf},
}

@subarticle{Sederberg.Smith.sub,
	author = {Sederberg, P. B. and Smith, T. A.},
	title = {Modeling the role of context and prediction in encoding variability},
	year = "Submitted",
}

@subarticle{OConnell.etal.sub,
	author = {O'Connell, T. and Sederberg, P. B. and Walther, D.},
	title = {Scene structure preserved in line drawings is sufficient to represent scene category but not scene identity in scene-selective cortex},
	year = "Submitted",
}

@article{Nielson.etal.2015,
  abstract = {Memory stretches over a lifetime. In controlled laboratory settings, the hippocampus and other medial temporal lobe brain structures have been shown to represent space and time on the scale of meters and seconds. It remains unclear whether the hippocampus also represents space and time over the longer scales necessary for human episodic memory. We recorded neural activity while participants relived their own experiences, cued by photographs taken with a custom lifelogging device. We found that the left anterior hippocampus represents space and time for a month of remembered events occurring over distances of up to 30 km. Although previous studies have identified similar drifts in representational similarity across space or time over the relatively brief time scales (seconds to minutes) that characterize individual episodic memories, our results provide compelling evidence that a similar pattern of spatiotemporal organization also exists for organizing distinct memories that are distant in space and time. These results further support the emerging view that the anterior, as opposed to posterior, hippocampus integrates distinct experiences, thereby providing a scaffold for encoding and retrieval of autobiographical memories on the scale of our lives.},
	author = {Nielson, D. M. and Smith, T. A. and Sreekumar, V. and Dennis, S. and Sederberg, P. B.},
	title = {Human hippocampus represents space and time during retrieval of real-world memories},
	volume = {112},
	number = {35},
	pages = {11078--11083},
	year = {2015},
	doi = {10.1073/pnas.1507104112},
	publisher = {National Academy of Sciences},
	number = {0027-8424},
	url = {http://www.pnas.org/content/112/35/11078},
	eprint = {http://www.pnas.org/content/112/35/11078.full.pdf},
	journal = {Proceedings of the National Academy of Sciences},
  pdf = {Nielson.etal.2015.pdf},
}

@subarticle{Gillespie.etal.sub,
	author = {Gillespie, M. J. and Smith, T. A. and Cunningham, W. A. and Sederberg, P. B.},
	date-added = {2014-03-08 16:37:53 +0000},
	date-modified = {2014-03-08 16:57:20 +0000},
	title = {Open to too much experience: Individual differences in personality predict false memory},
	year = "Submitted",
}

@article{vanVugt.etal.2007,
  abstract = {Spectral analysis methods are now routinely used in electrophysiological studies of human and animal cognition. Although a wide variety of spectral methods has been used, the ways in which these methods differ are not generally understood. Here we use simulation methods to characterize the similarities and differences between three spectral analysis methods: wavelets, multitapers and P(episode). P(episode) is a novel method that quantifies the fraction of time that oscillations exceed amplitude and duration thresholds. We show that wavelets and P(episode) used side-by-side helps to disentangle length and amplitude of a signal. P(episode) is especially sensitive to fluctuations around its thresholds, puts frequencies on a more equal footing, and is sensitive to long but low-amplitude signals. In contrast, multitaper methods are less sensitive to weak signals, but are very frequency-specific. If frequency specificity is not essential, then wavelets and P(episode) are recommended.},
	author = {{van Vugt}, M. K. and Sederberg, P. B. and Kahana, M. J.},
	journal = {Journal of Neuroscience Methods},
	number = {1-2},
	owner = {ageller},
	pages = {49--63},
	timestamp = {2007.03.18},
	title = {Comparison of spectral analysis methods for characterizing brain oscillations},
	volume = {162},
	year = {2007},
  pdf = {vanVugt.etal.2007.pdf},
}

@article{Gell.etal.2007,
  abstract = {PyEPL (the Python Experiment-Programming Library) is a Python library which allows cross-platform and object-oriented coding of behavioral experiments. It provides functions for displaying text and images onscreen, as well as playing and recording sound, and is capable of rendering 3-D virtual environments for spatial-navigation tasks. It is currently tested for Mac OS X and Linux. It interfaces with Activewire USB cards (on Mac OS X) and the parallel port (on Linux) for synchronization of experimental events with physiological recordings. In this article, we first present two sample programs which illustrate core PyEPL features. The examples demonstrate visual stimulus presentation, keyboard input, and simulation and exploration of a simple 3-D environment. We then describe the components and strategies used in implementing PyEPL.},
	author = {Geller, A. S. and Schleifer, I. K. and Sederberg, P. B. and Jacobs, J. and Kahana, M. J.},
	date-modified = {2007-11-09 16:14:58 -0500},
	journal = {Behavior Research Methods},
	number = {4},
	owner = {ageller},
	timestamp = {2006.03.13},
	title = {Py{EPL}: A Cross-Platform Experiment-Programming Library},
	volume = {39},
  pages = {950--958},
	year = {2007},
  pdf = {Gell.etal.2007.pdf},
}

@article{Gershman.etal.2012,
  abstract = {The successor representation was introduced into reinforcement learning by Dayan ( 1993 ) as a means of facilitating generalization between states with similar successors. Although reinforcement learning in general has been used extensively as a model of psychological and neural processes, the psychological validity of the successor representation has yet to be explored. An interesting possibility is that the successor representation can be used not only for reinforcement learning but for episodic learning as well. Our main contribution is to show that a variant of the temporal context model (TCM; Howard & Kahana, 2002 ), an influential model of episodic memory, can be understood as directly estimating the successor representation using the temporal difference learning algorithm (Sutton & Barto, 1998 ). This insight leads to a generalization of TCM and new experimental predictions. In addition to casting a new normative light on TCM, this equivalence suggests a previously unexplored point of contact between different learning systems.},
	author = {Gershman, S. J. and Moore, C. D. and Todd, M. T. and Norman, K. A. and Sederberg, P. B.},
	journal = {Neural Computation},
	number = {6},
	owner = {per},
	pages = {1553--1568},
	timestamp = {2012.02.12},
	title = {The successor representation and temporal context},
	volume = {24},
	year = {2012},
  pdf = {Gershman.etal.2012.pdf},
}

@article{Hank.etal.2009b,
  abstract = {Decoding patterns of neural activity onto cognitive states is one of the central goals of functional brain imaging. Standard univariate fMRI analysis methods, which correlate cognitive and perceptual function with the blood oxygenation-level dependent (BOLD) signal, have proven successful in identifying anatomical regions based on signal increases during cognitive and perceptual tasks. Recently, researchers have begun to explore new multivariate techniques that have proven to be more flexible, more reliable, and more sensitive than standard univariate analysis. Drawing on the field of statistical learning theory, these new classifier-based analysis techniques possess explanatory power that could provide new insights into the functional properties of the brain. However, unlike the wealth of software packages for univariate analyses, there are few packages that facilitate multivariate pattern classification analyses of fMRI data. Here we introduce a Python-based, cross-platform, and open-source software toolbox, called PyMVPA, for the application of classifier-based analysis techniques to fMRI datasets. PyMVPA makes use of Python's ability to access libraries written in a large variety of programming languages and computing environments to interface with the wealth of existing machine learning packages. We present the framework in this paper and provide illustrative examples on its usage, features, and programmability.},
	author = {Hanke, M. and Halchenko, Y. O. and Sederberg, P.B. and Hanson, S. J. and Haxby, J. V. and Pollmann, S.},
	journal = {Neuroinformatics},
	number = {1},
	pages = {37--53},
	publisher = {Springer},
	title = {{PyMVPA: A Python toolbox for multivariate pattern analysis of fMRI data}},
	volume = {7},
	year = {2009},
  pdf = {Hank.etal.2009b.pdf},
}

@inproceedings{Hank.etal.2009a,
  abstract = {The Python programming language is steadily increasing in popularity as the language of choice for scientific computing. The ability of this scripting environment to access a huge code base in various languages, combined with its syntactical simplicity, make it the ideal tool for implementing and sharing ideas among scientists from numerous fields and with heterogeneous methodological backgrounds. The recent rise of reciprocal interest between the machine learning (ML) and neuroscience communities is an example of the desire for an inter-disciplinary transfer of computational methods that can benefit from a Python-based framework. For many years, a large fraction of both research communities have addressed, almost independently, very high-dimensional problems with almost completely non-overlapping methods. However, a number of recently published studies that applied ML methods to neuroscience research questions attracted a lot of attention from researchers from both fields, as well as the general public, and showed that this approach can provide novel and fruitful insights into the functioning of the brain. In this article we show how PyMVPA, a specialized Python framework for machine learning based data analysis, can help to facilitate this inter-disciplinary technology transfer by providing a single interface to a wide array of machine learning libraries and neural data-processing methods. We demonstrate the general applicability and power of PyMVPA via analyses of a number of neural data modalities, including fMRI, EEG, MEG, and extracellular recordings.},
	author = {Hanke, M. and Halchenko, Y. O. and Sederberg, P. B. and Olivetti, E. and Frund, I. and Rieger, J. W. and Herrmann, C. S. and Hanson, S. J. and Haxby, J. V. and Pollmann, S.},
	doi = {doi:10.3389/neuro.11.003.2009},
	journal = {Fontiers in Neuroinformatics},
	owner = {sederberg},
	title = {PyMVPA: A Unifying Approach to the Analysis of Neuroscientific Data},
	volume = {3},
  pages = {3},
	year = {2009},
	url = {http://dx.doi.org/10.3389/neuro.11.003.2009},
  pdf = {Hank.etal.2009a.pdf},
}

@article{Hayes.etal.2011,
	__markedentry = {[per:6]},
  abstract = {Eye movements are an important data source in vision science. However,
	the vast majority of eye movement studies ignore sequential information
	in the data and utilize only first-order statistics. Here, we present
	a novel application of a temporal-difference learning algorithm to
	construct a scanpath successor representation (SR; P. Dayan, 1993)
	that captures statistical regularities in temporally extended eye
	movement sequences. We demonstrate the effectiveness of the scanpath
	SR on eye movement data from participants solving items from Raven's
	Advanced Progressive Matrices Test. Analysis of the SRs revealed
	individual differences in scanning patterns captured by two principal
	components that predicted individual Raven scores much better than
	existing methods. These scanpath SR components were highly interpretable
	and provided new insight into the role of strategic processing on
	the Raven test. The success of the scanpath SR in terms of prediction
	and interpretability suggests that this method could prove useful
	in a much broader context.},
	author = {Hayes, T. R. and Petrov, A. A. and Sederberg, P.B.},
	doi = {10.1167/11.10.10},
	institution = {Department of Psychology, Ohio State University, Columbus, OH 43210, USA. apetrov@alexpetrov.com},
	journal = {Journal of Vision},
	language = {eng},
	medline-pst = {epublish},
	number = {10},
	owner = {per},
	pages = {1--10},
	pii = {11.10.10},
	pmid = {21926182},
	timestamp = {2012.01.11},
	title = {A novel method for analyzing sequential eye movements reveals strategic influence on Raven's Advanced Progressive Matrices},
	url = {http://dx.doi.org/10.1167/11.10.10},
	volume = {11},
	year = {2011},
  pdf = {Hayes.etal.2011.pdf},
}

@article{Howard.etal.2008,
  abstract = {Space does not allow us to make detailed rebuttals to Davelaar, Usher, Haarmann, and Goshen-Gottstein's criticisms of the temporal context model's (TCM-A's) ability to account for dissociations between immediate and delayed recall nor to explain how TCM could account for list discrimination experiments. We agree that future work is needed to reach a satisfactory conclusion to these issues. Here we focus on their larger point that temporal context in TCM (Howard & Kahana, 2002) is best thought of as a new form of short-term store (STS). The designation STS carries with it connotations that are inconsistent with properties of temporal context that endows TCM with considerable explanatory power. We close with a proposal for a better way to reconcile Sederberg, Howard, and Kahana's (2008) TCM-A model and the Davelaar, Goshen-Gottstein, Ashkenazi, Haarmann, and Usher (2005) model.},
	author = {Howard, M. W. and Kahana, M. J. and Sederberg, P. B.},
	journal = {Psychological Review},
	owner = {sederberg},
	pages = {1125--1126},
	title = {Postscript: Distinguishing between temporal context and short-term store},
	volume = {115},
  number = {4},
	year = {2008},
  pdf = {Howard.etal.2008.pdf},
}

@article{Howard.etal.2009,
  abstract = {Farrell & Lewandowsky (2008) argue that the temporal context model (TCM; Howard & Kahana, 2002) cannot explain non-monotonicities in the contiguity effect seen at extreme lags. However TCM actually predicts that these non-monotonicities to the extent that end-of-list context persists as a retrieval cue during recall, and to the extent that end-of-list context generates a recency effect. We show that the observed non-monotonicity in the contiguity effect interacts with the recency effect as predicted by TCM. In conditions that exhibit strong recency, such as immediate and continual distractor free recall, one observes more prominent non-monotonicities in the contiguity effect than in conditions that attenuate recency, such as delayed free recall. Rather than posing a challenge to the model, the non-monotonicities in the contiguity effect at extreme lags and the interactions between recency and contiguity result from the role of end-of-list context as a retrieval cue in TCM.},
	author = {Howard, M. W and Sederberg, P. B. and Kahana, M. J.},
	journal = {Psychonomic Bulliten \& Review},
	owner = {sederberg},
	pages = {973--984},
	Timestamp = {2007.08.14},
	title = {Reply to Farrell and Lewandowsky: Changes in the shape of the lag-CRP predicted by TCM due to recency},
	volume = {16},
  number = {5},
	year = {2009},
  pdf = {Howard.etal.2009.pdf},
}

@article{Johnson.etal.2013,
  abstract = {Perceptual processing of a target stimulus may be inhibited if its location has just been cued, a phenomenon of spatial attention known as inhibition of return (IOR). In the research reported here, we demonstrated a striking effect, wherein items that have just been the focus of reflective attention (internal attention to an active representation) also are inhibited. Participants saw two items, followed by a cue to think back to (i.e., refresh, or direct reflective attention toward) one item, and then had to identify either the refreshed item, the unrefreshed item, or a novel item. Responses were significantly slower for refreshed items than for unrefreshed items, although refreshed items were better remembered on a later memory test. Control experiments in which we replaced the refresh event with a second presentation of one of the words did not show similar effects. These results suggest that reflective attention can produce an inhibition effect for attended items that may be analogous to IOR effects in perceptual attention.},
	author = {Johnson, M. R. and Higgins, J. A. and Norman, K. A. and Sederberg, P. B. and Smith, T. A. and Johnson, M. K.},
	date-modified = {2014-03-08 15:40:07 +0000},
	journal = {Psychological Science},
	number = {7},
	owner = {per},
	pages = {104--1112},
	timestamp = {2013.01.30},
	title = {Foraging for thought: an inhibition of return-like effect resulting from directing attention within working memory},
	volume = {24},
	year = {2013},
  pdf = {Johnson.etal.2013.pdf},
}

@article{Kahana.etal.2008,
  abstract = {The temporal context model posits that search through episodic memory is driven by associations between the multiattribute representations of items and context. Context, in turn, is a recency weighted sum of previous experiences or memories. Because recently processed items are most similar to the current representation of context, M. Usher, E. J. Davelaar, H. J. Haarmann, and Y. Goshen-Gottstein (2008) have suggested that the temporal context model (TCM-A) embodies a distinction between short-term and long-term memory and that this distinction is central to TCM-A's success in accounting for the pattern of recency and contiguity observed across short and long timescales. The authors dispute Usher et al's claim that context in TCM-A has much in common with classic interpretations of short-term memory. The idea that multiple representations interact in the process of memory encoding and retrieval (across timescales), as proposed in TCM-A, is very different from the classic dual-process view that distinct rules govern retrieval of recent and remote memories.},
	author = {Kahana, M. J. and Sederberg, P. B. and Howard, M. W.},
	date-added = {2008-07-15 10:28:07 -0400},
	date-modified = {2008-08-12 12:00:35 -0400},
	journal = {Psychological Review},
	pages = {1119--1125},
	title = {Putting short-term memory into context: {R}eply to {U}sher and colleagues},
	volume = {115},
  number = {4},
	year = {2008},
  pdf = {Kahana.etal.2008.pdf},
}

@inproceedings{Levy.Sederberg.1997,
  abstract = {In this paper a simple biological model of hippocampal region CA3 simulates the learning of hippocampally dependent trace classical conditioning. In this biologically based model, the time span of the associative modification rule is 5-fold less than the trace interval, implying that recurrent cell firing must play a significant role in encoding the trace interval. The results show that this simple network, with its moderate time spanning synaptic modification rule and sparse connectivity, can learn to span trace intervals comparable to those in rabbit eyeblink experiments. That is, the model learns to produce a cell firing pattern equivalent to an anticipatory unconditioned stimulus. This anticipatory pattern contains the information needed to intercept the unconditioned stimulus with a conditioned response because it is delivered at an appropriate time before the actual unconditioned stimulus.},
	author = {Levy, W. B and Sederberg, P. B.},
	journal = {IEEE International Conference on Neural Networks},
  volume = {1},
	pages = {372--376},
	title = {A Neural Network Model of Hippocampally Mediated Trace Conditioning},
	year = {1997},
  pdf = {Levy.Sederberg.1997.pdf},
}

@inproceedings{Levy.etal.1998,
  abstract = {The hippocampus is hypothesized to store memories of experiences during waking hours and then teach the cerebral cortex by broadcasting back this stored information during slow-wave sleep or during moments of wakeful inactivity1,2,3. Skaggs and McNaughton4 identified this rebroadcast in rats that experienced a repetitively sequenced experience. We have presented a hippocampal model of this phenomenon5,6 which spontaneously rebroadcasts previously learned sequential information. In addition to spontaneous recall, the model also replays the learned sequence information much faster than the original experience, a phenomenon known as temporal compression. The increases produced by the model, ranging from ten to forty-fold faster than the learned rate, are quite comparable to the reported compression observed experimentally by Skaggs and McNaughton4. In the model, two parameters are important for controlling the amount of temporal compression. The first is the overall level of activity (e.g., number of cell firings per timestep) and the second is the timespan of the rule governing associative synaptic modification. Increasing either of these parameters can produce more compression.},
	address = {New York},
	author = {Levy, W. B and Sederberg, P. B. and August, D.},
	booktitle = {Computational Neuroscience: Trends in Research},
	editor = {J.M.Bower},
	pages = {435--439},
	publisher = {Plenum Press},
  journal = {Computational Neuroscience: Trends in Research},
  volume = {J. M. Bower, Ed.},
	title = {Sequence Compression in a Hippocampal Model: A Functional Dissection},
	year = {1998},
  pdf = {Levy.etal.1998.pdf},
}

@article{Sederberg.etal.2006,
  abstract = {Both intracranial and scalp EEG studies have demonstrated that oscillatory activity, especially in the gamma band (28 to 100 Hz), can differentiate successful and unsuccessful episodic encoding [Sederberg, P.B., Kahana, M.J., Howard, M.W., Donner, E.J., Madsen, J.R., 2003. Theta and gamma oscillations during encoding predict subsequent recall. Journal of Neuroscience, 23(34), 10809-10814; Fell, J., Klaver, P., Lehnertz, K., Grunwald, T., Schaller, C., Elger, C.E., Fernandez, G., 2001. Human memory formation is accompanied by rhinal-hippocampal coupling and decoupling. Nature Neuroscience, 4 (12), 1259-1264; Gruber, T., Tsivilis, D., Montaldi, D., and Müller, M. (2004). Induced gamma band responses: An early marker of memory encoding and retrieval. Neuroreport, 15, 1837-1841; Summerfield, C., Mangels, J.A., in press. Dissociable neural mechanisms for encoding predictable and unpredictable events. Journal of Cognitive Neuroscience]. Although the probability of recalling an item varies as a function of where it appeared in the list, the relation between the oscillatory dynamics of successful encoding and serial position remains unexplored. We recorded scalp EEG as participants studied lists of common nouns in a delayed free-recall task. Because early list items were recalled better than items from later serial positions (the primacy effect), we analyzed encoding-related changes in 2 to 100 Hz oscillatory power as a function of serial position. Increases in gamma power in posterior regions predicted successful encoding at early serial positions; widespread low-frequency (4-14 Hz) power decreases predicted successful memory formation for later serial positions. These results suggest that items in early serial positions receive an encoding boost due to focused encoding without having to divide resources among numerous list items. Later in the list, as memory load increases, encoding is divided between multiple items.},
	author = {Sederberg, P. B. and Gauthier, L. V. and Terushkin, V. and Miller, J. F. and Barnathan, J. A. and Kahana, M. J.},
	journal = {NeuroImage},
	number = {3},
	pages = {1422--1431},
	title = {Oscillatory Correlates of the Primacy Effect in Episodic Memory},
	volume = {32},
	year = {2006},
  pdf = {Sederberg.etal.2006.pdf},
}

@article{Sederberg.etal.2011,
  abstract = {Recent work by Hupbach, Gomez, Hardt, and Nadel (Learning &amp; Memory,
  14, 47 --53, 2007) and Hupbach, Gomez, and Nadel (Memory, 17, 502--510,
  2009) suggests that episodic memory for a previously studied list
  can be updated to include new items, if participants are reminded
  of the earlier list just prior to learning a new list. The key finding
  from the Hupbach studies was an asymmetric pattern of intrusions,
  whereby participants intruded numerous items from the second list
  when trying to recall the first list, but not vice versa. Hupbach
  et al. (2007; 2009) explained this pattern in terms of a cellular
  reconsolidation process, whereby first-list memory is rendered labile
  by the reminder and the labile memory is then update d to include
  items from the second list. Here, we show that the temporal context
  model of memory, which lacks a cellular reconsolidation process,
  can account for the asymmetric intrusion effect, using well-established
  principles of contextual reinstatement and item--context binding.},
	affiliation = {Department of Psychology, The Ohio State University, Columbus, OH 43210, US A},
	author = {Sederberg, P. B. and Gershman, S. J. and Polyn, S. M. and Norman, K. A.},
	number = {1069-9384},
	number = {3},
	journal = {Psychonomic Bulletin \& Review},
	keyword = {Psychology},
	note = {10.3758/s13423-011-0086-9},
	pages = {455--468},
	publisher = {Springer New York},
	title = {Human memory reconsolidation can be explained using the temporal context model},
	url = {http://dx.doi.org/10.3758/s13423-011-0086-9},
	volume = {18},
	year = {2011},
  pdf = {Sederberg.etal.2011.pdf},
}

@article{Sederberg.etal.2008,
  abstract = {The authors present a new model of free recall on the basis of M. W. Howard and M. J. Kahana's temporal context model and M. Usher and J. L. McClelland's leaky-accumulator decision model. In this model, contextual drift gives rise to both short-term and long-term recency effects, and contextual retrieval gives rise to short-term and long-term contiguity effects. Recall decisions are controlled by a race between competitive leaky accumulators. The model captures the dynamics of immediate, delayed, and continual distractor free recall, demonstrating that dissociations between short- and long-term recency can naturally arise from a model in which an internal contextual state is used as the sole cue for retrieval across time scales.},
	author = {Sederberg, P. B. and Howard, M. W. and Kahana, M. J.},
	journal = {Psychological Review},
	owner = {sederberg},
	pages = {893--912},
	timestamp = {2007.08.14},
	title = {A context-based theory of recency and contiguity in free recall},
	volume = {115},
  number = {4},
	year = {2008},
  pdf = {Sederberg.etal.2008.pdf},
}

@article{Sederberg.etal.2003,
  abstract = {Electrophysiological and hemodynamic measures of human brain activity have been shown to distinguish between episodes of encoding items that are later recalled versus those that are not recalled (Paller and Wagner, 2002). Using intracranial recordings from 793 widespread cortical and subcortical sites in 10 epileptic patients undergoing invasive monitoring, we compared oscillatory power at frequencies ranging from 2 to 64 Hz as participants studied lists of common nouns. Significant increases in oscillatory power during encoding predicted subsequent recall, with this effect predominantly in the 4-8 Hz (theta) and 28-64 Hz (gamma) frequency bands. Sites exhibiting increased theta activity during successful encoding were clustered in right temporal and frontal cortex, whereas those exhibiting increased gamma activity appeared bilaterally at widespread cortical locations. These findings implicate theta and gamma oscillatory activity, across a widespread network of cortical regions, in the formation of new episodic memories.},
	author = {Sederberg, P. B. and Kahana, M. J. and Howard, M. W. and Donner, E. J. and Madsen, J. R.},
	date-modified = {2007-02-05 16:11:47 -0500},
	journal = {Journal of Neuroscience},
	number = {34},
	pages = {10809--10814},
	title = {Theta and gamma oscillations during encoding predict subsequent recall},
	volume = {23},
	year = {2003},
  pdf = {Sederberg.etal.2003.pdf},
}

@article{Sederberg.etal.2010,
  abstract = {One way to study the associative processes at work during episodic memory is to examine the order of participant responses, which reveal the strong tendency to transition between temporally contiguous or semantically proximal items on the study list. Here, we assessed the correlation between participants' recall performance and their use of semantic and temporal associations to guide retrieval across nine delayed free recall studies. The size of the participants' temporal contiguity effects predicted their recall performance. When interpreted in terms of two models of episodic memory, these results suggest that participants who more effectively form and retrieve associations between items that occur nearby in time perform better on episodic recall tasks. Sample code may be downloaded as a supplement for this article from http://mc.psychonomic-journals.org/content/supplemental.},
	author = {Sederberg, P. B. and Miller, J. F. and Howard, M. W and Kahana, M. J.},
	journal = {Memory \& Cognition},
	pages = {689--699},
	title = {The temporal contiguity effect predicts episodic memory performance},
	volume = {38},
  number = {6},
	year = {2010},
  pdf = {Sederberg.etal.2010.pdf},
}

@article{Sederberg.etal.2007b,
  abstract = {To test whether distinct patterns of electrophysiological activity prior to a response can distinguish true from false memories, we analyzed intracranial electroencephalographic recordings while 52 patients undergoing treatment for epilepsy performed a verbal free-recall task. These analyses revealed that the same pattern of gamma-band (28–100 Hz) oscillatory activity that predicts successful memory formation at item encoding—increased gamma power in the hippocampus, prefrontal cortex, and left temporal lobe—reemerges at retrieval to distinguish correct from incorrect responses. The timing of these oscillatory effects suggests that self-cued memory retrieval begins in the hippocampus and then spreads to the cortex. Thus, retrieval of true, as compared with false, memories induces a distinct pattern of gamma oscillations, possibly reflecting recollection of contextual information associated with past experience.},
	author = {Sederberg, P. B. and Schulze-Bonhage, A. and Madsen, J. R. and Bromfield, E. B. and Litt, B. and Brandt, A. and Kahana, M. J.},
	journal = {Psychological Science},
	number = {11},
	pages = {927--932},
	title = {Gamma oscillations distinguish true from false memories},
	volume = {18},
	year = {2007},
  pdf = {Sederberg.etal.2007b.pdf},
  supp = {Sederberg.etal.2007b.supp.pdf},
}

@article{Sederberg.etal.2007a,
  abstract = {Functional magnetic resonance imaging (fMRI) of the human brain has shown that the hippocampus and the left temporal and frontal cortices play a key role in the formation of new verbal memories. We recorded electrical activity from 2349 surgically implanted intracranial electrodes in epilepsy patients while they studied and later recalled lists of common words. Using these recordings, we demonstrate that gamma oscillations (44-64 Hz) in the hippocampus and the left temporal and frontal cortices predict successful encoding of new verbal memories. This increase in gamma oscillations was not seen in other frequency bands, whose activity generally decreased during successful memory formation. These findings identify a role for gamma oscillations in verbal memory formation with the hippocampus and the left temporal and frontal cortices, the same regions implicated using noninvasive fMRI recording methods.},
	author = {Sederberg, P. B. and Schulze-Bonhage, A. and Madsen, J. R. and Bromfield, E. B. and McCarthy, D. C. and Brandt, A. and Tully, M. S. and Kahana, M. J.},
	journal = {Cerebral Cortex},
	number = {5},
	owner = {ageller},
	pages = {1190--1196},
	timestamp = {2007.03.18},
	title = {Hippocampal and neocortical gamma oscillations predict memory formation in humans},
	volume = {17},
	year = {2007},
  pdf = {Sederberg.etal.2007a.pdf},
}

@article{Serruya.etal.2014,
  abstract = {The first events in a series exert a powerful influence on cognition and behavior in both humans and animals. This is known as the law of primacy. Here, we analyze the neural correlates of primacy in humans by analyzing electrocorticographic recordings in 84 neurosurgical patients as they studied and subsequently recalled lists of common words. We found that spectral power in the gamma frequency band (28-100 Hz) was elevated at the start of the list and gradually subsided, whereas lower frequency (2-8 Hz) delta and theta band power exhibited the opposite trend. This gradual shift in the power spectrum was found across a widespread network of brain regions. The degree to which the subsequent memory effect was modulated by list (serial) position was most pronounced in medial temporal lobe structures. These results suggest that globally increased gamma and decreased delta-theta spectral powers reflect a brain state that predisposes medial temporal lobe structures to enhance the encoding and maintenance of early list items.},
	author = {Serruya, M. D. and Sederberg, P. B. and Kahana, M. J.},
	date-modified = {2014-03-08 15:34:48 +0000},
	journal = {Cerebral Cortex},
	number = {2},
	pages = {403--413},
	title = {Power shifts track serial position and modulate encoding in human episodic memory},
	volume = {24},
	year = {2014},
  pdf = {Serruya.etal.2014.pdf},
}

@article{Smith.etal.2013,
  abstract = {A key function of the medial temporal lobe (MTL) is to generate predictions based on prior experience (Bar, 2009). We propose that these MTL-generated predictions guide learning, such that predictions from memory influence memory itself. Considering this proposal within a context-based theory of learning and memory leads to the unique hypothesis that the act of predicting an event from the current context can enhance later memory for that event, even if the event does not actually occur. We tested this hypothesis using a novel paradigm in which the contexts of some stimuli were repeated during an incidental learning task, without the stimuli themselves being repeated. Results from 4 experiments show clear behavioral evidence in support of this hypothesis: Participants were more likely to remember once-presented items if the temporal contexts of those items were later repeated. However, this effect only occurred in learning environments where predictions could be helpful.},
	author = {Smith, T. A. and Hasinski, A. E. and Sederberg, P. B.},
	date-modified = {2014-03-08 15:26:01 +0000},
	journal = {Journal of Experimental Psychology: General},
	number = {4},
	pages = {1298--1308},
	title = {The Context Repetition Effect: Predicted Events are Remembered Better, Even When They Don't Happen},
	volume = {142},
	year = {2013},
  pdf = {Smith.etal.2013.pdf},
}

@subarticle{Smith.Sederberg.sub,
	author = {Smith, T. A. and Sederberg, P. B.},
	title = {Low frequency neural oscillations during encoding reveal interactions between semantic relatedness, subsequent memory, and subsequent false memory},
	year = "Submitted",
}

@article{Solway.etal.2010,
  abstract = {Studies of human memory often generate data on the sequence and timing of recalled items, but scoring such data using conventional methods is difficult or impossible. We describe a Python-based semiautomated system that greatly simplifies this task. This software, called PyParse, can easily be used in conjunction with many common experiment authoring systems. Scored data is output in a simple ASCII format and can be accessed with the programming language of choice, allowing for the identification of features such as correct responses, prior-list intrusions, extra-list intrusions, and repetitions.},
	author = {Solway, A. and Geller, A. S. and Sederberg, P. B. and Kahana, M. J.},
	journal = {Behavior Research Methods},
	number = {1},
	pages = {141--147},
	publisher = {Springer},
	title = {PyParse: A semiautomated system for scoring spoken recall data},
	volume = {42},
	year = {2010},
  pdf = {Solway.etal.2010.pdf},
}

@article{Turk-Browne.etal.2012,
  abstract = {Human perception is supported by regions of ventral visual cortex that become active when specific types of information appear in the environment. This coupling has led to a common assumption in cognitive neuroscience that stimulus-evoked activity in these regions only reflects information about the current stimulus. Here we challenge this assumption for how scenes are represented in a scene-selective region of parahippocampal cortex. This region treated two identical scenes as more similar when they were preceded in time by the same stimuli compared to when they were preceded by different stimuli. These findings suggest that parahippocampal cortex embeds scenes in their temporal context in order to determine what they represent. By integrating the past and present, such representations may support the encoding and navigation of complex environments.},
	author = {Turk-Browne, N. B. and Simon, M. G. and Sederberg, P. B.},
	journal = {The Journal of Neuroscience},
	number = {21},
	pages = {7202--7207},
	publisher = {Society for Neuroscience},
	title = {Scene representations in parahippocampal cortex depend on temporal context},
	volume = {32},
	year = {2012},
  pdf = {Turk-Browne.etal.2012.pdf},
}

@inproceedings{Turner.etal.2013a,
  abstract = {Scientists who study cognition infer underlying processes either by observing behavior (e.g., response times, percentage correct) or by observing neural activity (e.g., the BOLD response). These two types of observations have traditionally supported two separate lines of study. The first is led by cognitive modelers, who rely on behavior alone to support their computational theories. The second is led by cognitive neuroimagers, who rely on statistical models to link patterns of neural activity to experimental manipulations, often without any attempt to make a direct connection to an explicit computational theory. Here we present a flexible Bayesian framework for combining neural and cognitive models. Joining neuroimaging and computational modeling in a single hierarchical framework allows the neural data to influence the parameters of the cognitive model and allows behavioral data, even in the absence of neural data, to constrain the neural model. Critically, our Bayesian approach can reveal interactions between behavioral and neural parameters, and hence between neural activity and cognitive mechanisms. We demonstrate the utility of our approach with applications to simulated fMRI data with a recognition model and to diffusion-weighted imaging data with a response time model of perceptual choice.},
	author = {Turner, B. M. and Forstmann, B. U. and Wagenmakers, E.-J. and Brown, S. D. and P. B. Sederberg and Steyvers, M.},
	date-modified = {2014-03-08 15:42:45 +0000},
	journal = {NeuroImage},
	pages = {193--206},
	title = {A {B}ayesian framework for simultaneously modeling neural and behavioral data},
	volume = {72},
	year = {2013},
  pdf = {Turner.etal.2013a.pdf},
  supp = {Turner.etal.2013a.supp.pdf},
}

@article{Turner.Sederberg.2012,
  abstract = {Approximate Bayesian computation {(ABC)} is a simulation-based method
  for estimating the posterior distribution of the parameters of a
  model. The {ABC} approach is instrumental when a likelihood function
  for a model cannot be mathematically specified, or has a complicated
  form. Although difficulty in calculating a model's likelihood is
  extremely common, current {ABC} methods suffer from two problems
  that have largely prevented their mainstream adoption: long computation
  time and an inability to scale beyond a few parameters. We introduce
  differential evolution as a computationally efficient genetic algorithm
  for proposal generation in our {ABC} sampler. We show how using
  this method allows our new {ABC} algorithm, called {ABCDE}, to obtain
  accurate posterior estimates in fewer iterations than kernel-based
  {ABC} algorithms and to scale to high-dimensional parameter spaces
  that have proven difficult for current {ABC} methods.},
	author = {Turner, B. M. and Sederberg, P. B.},
	date-modified = {2014-03-08 15:51:59 +0000},
	doi = {10.1016/j.jmp.2012.06.004},
	file = {ScienceDirect Snapshot:/home/per/.mozilla/firefox/4okd6j1e.defa ult/zotero/storage/PZR2N2D3/S0022249612000752.html:text/html},
	number = {0022-2496},
	journal = {Journal of Mathematical Psychology},
	keywords = {Approximate Bayesian computation, Computational modeling, Differential evolution, Likelihood-free inference},
	number = {5},
	pages = {375--385},
	title = {Approximate Bayesian computation with differential evolution},
	url = {http://www.sciencedirect.com/science/article/pii/S00222496120007 52},
	volume = {56},
	year = {2012},
	doi = {http://dx.doi.org/10.1016/j.jmp.2012.06.004},
  pdf = {Turner.Sederberg.2012.pdf},
}

@article{Turner.etal.2013b,
  abstract = {Bayesian estimation has played a pivotal role in the understanding of individual differences. However, for many models in psychology, Bayesian estimation of model parameters can be difficult. One reason for this difficulty is that conventional sampling algorithms, such as Markov chain Monte Carlo (MCMC), can be inefficient and impractical when little is known about the target distribution--particularly the target distribution's covariance structure. In this article, we highlight some reasons for this inefficiency and advocate the use of a population MCMC algorithm, called differential evolution Markov chain Monte Carlo (DE-MCMC), as a means of efficient proposal generation. We demonstrate in a simulation study that the performance of the DE-MCMC algorithm is unaffected by the correlation of the target distribution, whereas conventional MCMC performs substantially worse as the correlation increases. We then show that the DE-MCMC algorithm can be used to efficiently fit a hierarchical version of the linear ballistic accumulator model to response time data, which has proven to be a difficult task when conventional MCMC is used.},
	author = {Turner, B. M. and Sederberg, P. B. and Brown, S. and Steyvers, M.},
	title = {A method for efficiently sampling from distributions with correlated dimensions},
  journal = {Psychological Methods},
	year = {2013},
  volume = {18},
  number = {3},
  pages = {368--384},
  pdf = {Turner.etal.2013b.pdf},
}

@inproceedings{Socher.etal.2009,
  abstract = {We develop a probabilistic model of human memory performance in free recall experiments. In these experiments, a subject first studies a list of words and then tries to recall them. To model these data, we draw on both previous psychological research and statistical topic models of text documents. We assume that memories are formed by assimilating the semantic meaning of studied words (represented as a distribution over topics) into a slowly changing latent context (represented in the same space). During recall, this context is reinstated and used as a cue for retrieving studied words. By conceptualizing memory retrieval as a dynamic latent variable model, we are able to use Bayesian inference to represent uncertainty and reason about the cognitive processes underlying memory. We present a particle filter algorithm for performing approximate posterior inference, and evaluate our model on the prediction of recalled words in experimental data. By specifying the model hierarchically, we are also able to capture inter-subject variability.},
	author = {Socher, R. and Gershman, S. J. and Sederberg, P. B. and Norman, K. A. and Perotte, A. J. and Blei, D. M.},
	booktitle = {Advances in neural information processing systems},
	pages = {1714--1722},
	title = {A bayesian analysis of dynamics in free recall},
  journal = {Advances in Neural Information Processing Systems},
  volume = {22},
	year = {2009},
  pdf = {Socher.etal.2009.pdf},
}